{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Strategy import RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-26 13:40:47,300] Making new env: Swimmer-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-26 13:40:48,454] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CASE 1\n",
      "  Exp : epsilon\n",
      "  Strategy : Double : True, Dueling : True, Prioritized : True\n",
      "1           9.042\n",
      "                   ( Result : 9.04174,  Loss : 0.01552445,  epsilon : 1.0 )\n",
      "2           10.889\n",
      "                   ( Result : 12.73586,  Loss : 0.02953841,  epsilon : 1.0 )\n",
      "3           2.16\n",
      "                   ( Result : -15.29711,  Loss : 0.05701494,  epsilon : 1.0 )\n",
      "4           -0.386\n",
      "                   ( Result : -8.02297,  Loss : 0.06990337,  epsilon : 1.0 )\n",
      "5           3.828\n",
      "                   ( Result : 20.68046,  Loss : 0.11674106,  epsilon : 0.5 )\n",
      "6           7.505\n",
      "                   ( Result : 25.88924,  Loss : 0.12376723,  epsilon : 0.5 )\n",
      "7           9.321\n",
      "                   ( Result : 20.2227,  Loss : 0.23368527,  epsilon : 0.5 )\n",
      "8           10.63\n",
      "                   ( Result : 19.79124,  Loss : 0.19187537,  epsilon : 0.5 )\n",
      "9           8.204\n",
      "                   ( Result : -11.20956,  Loss : 0.17828757,  epsilon : 0.333 )\n",
      "10           9.423\n",
      "                   ( Result : 20.40288,  Loss : 0.21438095,  epsilon : 0.333 )\n",
      "11           9.201\n",
      "                   ( Result : 6.97141,  Loss : 0.26010424,  epsilon : 0.333 )\n",
      "12           10.129\n",
      "                   ( Result : 20.33724,  Loss : 0.18039189,  epsilon : 0.333 )\n",
      "13           12.127\n",
      "                   ( Result : 36.10211,  Loss : 0.30317986,  epsilon : 0.25 )\n",
      "14           12.901\n",
      "                   ( Result : 22.96641,  Loss : 0.21537025,  epsilon : 0.25 )\n",
      "15           13.559\n",
      "                   ( Result : 22.77233,  Loss : 0.20617579,  epsilon : 0.25 )\n",
      "16           12.564\n",
      "                   ( Result : -2.35977,  Loss : 0.25313625,  epsilon : 0.25 )\n",
      "17           13.459\n",
      "                   ( Result : 27.77594,  Loss : 0.23136416,  epsilon : 0.2 )\n",
      "18           12.743\n",
      "                   ( Result : 0.5753,  Loss : 0.26431575,  epsilon : 0.2 )\n",
      "19           11.98\n",
      "                   ( Result : -1.74734,  Loss : 0.17510517,  epsilon : 0.2 )\n",
      "20           11.437\n",
      "                   ( Result : 1.11321,  Loss : 0.1552476,  epsilon : 0.2 )\n",
      "21           12.078\n",
      "                   ( Result : 24.89451,  Loss : 0.20064779,  epsilon : 0.167 )\n",
      "22           10.951\n",
      "                   ( Result : -12.72466,  Loss : 0.5126707,  epsilon : 0.167 )\n",
      "23           10.927\n",
      "                   ( Result : 10.41041,  Loss : 0.19198652,  epsilon : 0.167 )\n",
      "24           11.388\n",
      "                   ( Result : 21.97853,  Loss : 0.21474622,  epsilon : 0.167 )\n",
      "25           10.984\n",
      "                   ( Result : 1.30093,  Loss : 0.21247795,  epsilon : 0.143 )\n",
      "26           10.775\n",
      "                   ( Result : 5.54227,  Loss : 0.52144766,  epsilon : 0.143 )\n",
      "27           11.205\n",
      "                   ( Result : 22.39225,  Loss : 0.32110527,  epsilon : 0.143 )\n",
      "28           10.559\n",
      "                   ( Result : -6.88706,  Loss : 0.26578557,  epsilon : 0.143 )\n",
      "29           10.513\n",
      "                   ( Result : 9.22159,  Loss : 0.26225829,  epsilon : 0.125 )\n",
      "30           10.454\n",
      "                   ( Result : 8.73853,  Loss : 0.21737662,  epsilon : 0.125 )\n",
      "31           10.668\n",
      "                   ( Result : 17.10527,  Loss : 0.6571458,  epsilon : 0.125 )\n",
      "32           10.812\n",
      "                   ( Result : 15.25616,  Loss : 0.34727001,  epsilon : 0.125 )\n",
      "33           10.973\n",
      "                   ( Result : 16.13688,  Loss : 0.53788203,  epsilon : 0.111 )\n",
      "34           11.503\n",
      "                   ( Result : 29.00604,  Loss : 0.27777416,  epsilon : 0.111 )\n",
      "35           11.409\n",
      "                   ( Result : 8.20381,  Loss : 0.75218964,  epsilon : 0.111 )\n",
      "36           11.543\n",
      "                   ( Result : 16.21915,  Loss : 0.33161262,  epsilon : 0.111 )\n",
      "37           11.935\n",
      "                   ( Result : 26.07615,  Loss : 0.13645881,  epsilon : 0.1 )\n",
      "38           11.963\n",
      "                   ( Result : 12.98063,  Loss : 0.42506853,  epsilon : 0.1 )\n",
      "39           12.541\n",
      "                   ( Result : 34.50845,  Loss : 0.41365597,  epsilon : 0.1 )\n",
      "40           12.883\n",
      "                   ( Result : 26.19946,  Loss : 0.78717023,  epsilon : 0.1 )\n",
      "41           13.322\n",
      "                   ( Result : 30.88409,  Loss : 0.22902595,  epsilon : 0.091 )\n",
      "42           13.54\n",
      "                   ( Result : 22.47947,  Loss : 0.52452052,  epsilon : 0.091 )\n",
      "43           13.513\n",
      "                   ( Result : 12.37571,  Loss : 0.81043661,  epsilon : 0.091 )\n",
      "44           13.318\n",
      "                   ( Result : 4.97223,  Loss : 0.34697339,  epsilon : 0.091 )\n",
      "45           13.427\n",
      "                   ( Result : 18.18498,  Loss : 0.62406105,  epsilon : 0.083 )\n",
      "46           13.542\n",
      "                   ( Result : 18.73551,  Loss : 0.52550262,  epsilon : 0.083 )\n",
      "47           13.66\n",
      "                   ( Result : 19.11036,  Loss : 0.640158,  epsilon : 0.083 )\n",
      "48           13.789\n",
      "                   ( Result : 19.8069,  Loss : 0.37731197,  epsilon : 0.083 )\n",
      "49           13.668\n",
      "                   ( Result : 7.86578,  Loss : 0.63262165,  epsilon : 0.077 )\n",
      "50           14.023\n",
      "                   ( Result : 31.41935,  Loss : 0.78444237,  epsilon : 0.077 )\n",
      "51           14.083\n",
      "                   ( Result : 17.11935,  Loss : 0.81693286,  epsilon : 0.077 )\n",
      "52           14.298\n",
      "                   ( Result : 25.22443,  Loss : 0.79103756,  epsilon : 0.077 )\n",
      "53           14.15\n",
      "                   ( Result : 6.4849,  Loss : 0.884341,  epsilon : 0.071 )\n",
      "54           14.312\n",
      "                   ( Result : 22.90847,  Loss : 0.74559611,  epsilon : 0.071 )\n",
      "55           14.51\n",
      "                   ( Result : 25.16677,  Loss : 1.12858188,  epsilon : 0.071 )\n",
      "56           14.64\n",
      "                   ( Result : 21.7796,  Loss : 0.83912647,  epsilon : 0.071 )\n",
      "57           14.729\n",
      "                   ( Result : 19.7236,  Loss : 0.41468427,  epsilon : 0.067 )\n",
      "58           14.93\n",
      "                   ( Result : 26.42364,  Loss : 0.34138882,  epsilon : 0.067 )\n",
      "59           15.274\n",
      "                   ( Result : 35.17363,  Loss : 0.32858586,  epsilon : 0.067 )\n",
      "60           15.466\n",
      "                   ( Result : 26.82817,  Loss : 0.48157415,  epsilon : 0.067 )\n",
      "61           15.917\n",
      "                   ( Result : 42.94073,  Loss : 0.60410225,  epsilon : 0.063 )\n",
      "62           15.944\n",
      "                   ( Result : 17.62053,  Loss : 0.71094143,  epsilon : 0.063 )\n",
      "63           15.999\n",
      "                   ( Result : 19.43289,  Loss : 1.38945866,  epsilon : 0.063 )\n",
      "64           16.191\n",
      "                   ( Result : 28.25522,  Loss : 0.39489582,  epsilon : 0.063 )\n",
      "65           16.227\n",
      "                   ( Result : 18.51567,  Loss : 0.75957227,  epsilon : 0.059 )\n",
      "66           16.25\n",
      "                   ( Result : 17.74045,  Loss : 0.77658629,  epsilon : 0.059 )\n",
      "67           16.478\n",
      "                   ( Result : 31.53725,  Loss : 0.33639923,  epsilon : 0.059 )\n",
      "68           16.526\n",
      "                   ( Result : 19.75777,  Loss : 0.37104991,  epsilon : 0.059 )\n",
      "69           16.732\n",
      "                   ( Result : 30.74619,  Loss : 0.46959797,  epsilon : 0.056 )\n",
      "70           17.011\n",
      "                   ( Result : 36.23992,  Loss : 0.74170858,  epsilon : 0.056 )\n",
      "71           17.083\n",
      "                   ( Result : 22.11824,  Loss : 0.5396418,  epsilon : 0.056 )\n",
      "72           17.182\n",
      "                   ( Result : 24.25188,  Loss : 0.60357332,  epsilon : 0.056 )\n",
      "73           17.268\n",
      "                   ( Result : 23.4173,  Loss : 0.33225092,  epsilon : 0.053 )\n",
      "74           17.389\n",
      "                   ( Result : 26.2182,  Loss : 1.00014639,  epsilon : 0.053 )\n",
      "75           17.562\n",
      "                   ( Result : 30.39671,  Loss : 0.56600076,  epsilon : 0.053 )\n",
      "76           17.691\n",
      "                   ( Result : 27.34394,  Loss : 0.72225022,  epsilon : 0.053 )\n",
      "77           17.898\n",
      "                   ( Result : 33.67585,  Loss : 0.66572368,  epsilon : 0.05 )\n",
      "78           17.935\n",
      "                   ( Result : 20.7746,  Loss : 0.82712507,  epsilon : 0.05 )\n",
      "79           18.078\n",
      "                   ( Result : 29.19131,  Loss : 0.85167629,  epsilon : 0.05 )\n",
      "80           18.163\n",
      "                   ( Result : 24.89767,  Loss : 0.90535527,  epsilon : 0.05 )\n",
      "81           18.38\n",
      "                   ( Result : 35.77979,  Loss : 0.80132341,  epsilon : 0.048 )\n",
      "82           18.364\n",
      "                   ( Result : 17.025,  Loss : 0.59274536,  epsilon : 0.048 )\n",
      "83           18.329\n",
      "                   ( Result : 15.48376,  Loss : 0.93806618,  epsilon : 0.048 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84           18.543\n",
      "                   ( Result : 36.3218,  Loss : 0.80434567,  epsilon : 0.048 )\n",
      "85           18.566\n",
      "                   ( Result : 20.43512,  Loss : 0.6086455,  epsilon : 0.045 )\n",
      "86           18.642\n",
      "                   ( Result : 25.12422,  Loss : 0.21650195,  epsilon : 0.045 )\n",
      "87           18.863\n",
      "                   ( Result : 37.87294,  Loss : 0.64193189,  epsilon : 0.045 )\n",
      "88           19.057\n",
      "                   ( Result : 35.89602,  Loss : 0.51495171,  epsilon : 0.045 )\n",
      "89           19.213\n",
      "                   ( Result : 33.01146,  Loss : 1.0821569,  epsilon : 0.043 )\n"
     ]
    }
   ],
   "source": [
    "case_num = 3\n",
    "\n",
    "# 1 : epsilon , 2 : softmax , 3 : sparsemax , 4 : sparse+eps\n",
    "Exp_list = ['epsilon', 'sparse+eps', 'softmax']\n",
    "\n",
    "Double_list = [True, True, True]\n",
    "Dueling_list = [True, True, True]\n",
    "Prioritized_list = [True, True, True]\n",
    "\n",
    "action_res_list = [51, 51]\n",
    "#seed_list = [0, 0, 0]\n",
    "\n",
    "#batch_list = [32, 64, 128]\n",
    "l_rate_list = [0.0002, 0.001, 0.002]\n",
    "\n",
    "#t_step_list = [1, 5, 10]\n",
    "#c_step_list = [4, 20, 40]\n",
    "\n",
    "for i in range(case_num):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess :\n",
    "        CartPole = RL(sess, dis = 0.99, REPLAY_MEMORY = 100000, max_episodes = 200, action_res = action_res_list,\n",
    "                      \n",
    "                      batch_size = 256, training_step = 100, copy_step = 100,\n",
    "                      eps_div = 4, repu_num = 4,\n",
    "                      layer_size = 512, learning_rate = l_rate_list[i],\n",
    "                      \n",
    "                      alpha = 0.6, beta_init = 0.4, eps = 0.01, save_epi = 100,\n",
    "                      ending_cond_epis = 100, ending_cond_reward = 360,\n",
    "                      Game = 'Swimmer-v1')\n",
    "    \n",
    "        CartPole.run_RL(case_n = i+1, Exp = Exp_list[i], seed_n = 0,\n",
    "                       Double = Double_list[i], Dueling = Dueling_list[i], Prioritized = Prioritized_list[i])\n",
    "    sess.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
