{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "[2018-03-10 08:59:31,045] Making new env: Swimmer-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-03-10 08:59:31,645] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CASE 1\n",
      "  STATE DIM : 8, ACTION DIM : 2\n",
      "  Exp : epsilon\n",
      "  Strategy : Double : True, Dueling : True, Prioritized : False\n",
      "1           -2.048\n",
      "                   ( Result : -2.04797,  Loss : 0.0,  Epsilon : 1.0,  Steps : 1000,  Global Steps : 1000 )\n",
      "2           5.494\n",
      "                   ( Result : 13.03664,  Loss : 0.0,  Epsilon : 0.98462,  Steps : 1000,  Global Steps : 2000 )\n",
      "3           2.239\n",
      "                   ( Result : -4.27189,  Loss : 0.0,  Epsilon : 0.9697,  Steps : 1000,  Global Steps : 3000 )\n",
      "4           1.301\n",
      "                   ( Result : -1.5117,  Loss : 0.0,  Epsilon : 0.95522,  Steps : 1000,  Global Steps : 4000 )\n",
      "5           0.887\n",
      "                   ( Result : -0.76894,  Loss : 0.0,  Epsilon : 0.94118,  Steps : 1000,  Global Steps : 5000 )\n",
      "6           -1.649\n",
      "                   ( Result : -14.32965,  Loss : 0.0,  Epsilon : 0.92754,  Steps : 1000,  Global Steps : 6000 )\n",
      "7           -4.542\n",
      "                   ( Result : -21.89784,  Loss : 0.0,  Epsilon : 0.91429,  Steps : 1000,  Global Steps : 7000 )\n",
      "8           -6.088\n",
      "                   ( Result : -16.91595,  Loss : 0.0,  Epsilon : 0.90141,  Steps : 1000,  Global Steps : 8000 )\n",
      "9           -5.459\n",
      "                   ( Result : -0.42433,  Loss : 0.0,  Epsilon : 0.88889,  Steps : 1000,  Global Steps : 9000 )\n",
      "10           -4.649\n",
      "                   ( Result : 2.64498,  Loss : 0.0,  Epsilon : 0.87671,  Steps : 1000,  Global Steps : 10000 )\n",
      "11           -4.298\n",
      "                   ( Result : -0.78718,  Loss : 0.0,  Epsilon : 0.86486,  Steps : 1000,  Global Steps : 11000 )\n",
      "12           -2.723\n",
      "                   ( Result : 14.59447,  Loss : 0.0,  Epsilon : 0.85333,  Steps : 1000,  Global Steps : 12000 )\n",
      "13           -2.864\n",
      "                   ( Result : -4.55132,  Loss : 0.0,  Epsilon : 0.84211,  Steps : 1000,  Global Steps : 13000 )\n",
      "14           -2.834\n",
      "                   ( Result : -2.44348,  Loss : 0.0,  Epsilon : 0.83117,  Steps : 1000,  Global Steps : 14000 )\n",
      "15           -1.464\n",
      "                   ( Result : 17.715,  Loss : 0.0,  Epsilon : 0.82051,  Steps : 1000,  Global Steps : 15000 )\n",
      "16           -1.479\n",
      "                   ( Result : -1.71055,  Loss : 0.0,  Epsilon : 0.81013,  Steps : 1000,  Global Steps : 16000 )\n",
      "17           -1.232\n",
      "                   ( Result : 2.72159,  Loss : 0.0,  Epsilon : 0.8,  Steps : 1000,  Global Steps : 17000 )\n",
      "18           0.591\n",
      "                   ( Result : 31.57888,  Loss : 0.0,  Epsilon : 0.79012,  Steps : 1000,  Global Steps : 18000 )\n",
      "19           -0.273\n",
      "                   ( Result : -15.82192,  Loss : 0.0,  Epsilon : 0.78049,  Steps : 1000,  Global Steps : 19000 )\n",
      "20           2.242\n",
      "                   ( Result : 50.03629,  Loss : 0.0,  Epsilon : 0.77108,  Steps : 1000,  Global Steps : 20000 )\n",
      "21           1.607\n",
      "                   ( Result : -11.09146,  Loss : 0.0,  Epsilon : 0.7619,  Steps : 1000,  Global Steps : 21000 )\n",
      "22           1.63\n",
      "                   ( Result : 2.0984,  Loss : 0.0,  Epsilon : 0.75294,  Steps : 1000,  Global Steps : 22000 )\n",
      "23           0.702\n",
      "                   ( Result : -19.70462,  Loss : 0.0,  Epsilon : 0.74419,  Steps : 1000,  Global Steps : 23000 )\n",
      "24           0.535\n",
      "                   ( Result : -3.31271,  Loss : 0.0,  Epsilon : 0.73563,  Steps : 1000,  Global Steps : 24000 )\n",
      "25           0.386\n",
      "                   ( Result : -3.19452,  Loss : 0.0,  Epsilon : 0.72727,  Steps : 1000,  Global Steps : 25000 )\n",
      "26           0.02\n",
      "                   ( Result : -9.13179,  Loss : 0.0,  Epsilon : 0.7191,  Steps : 1000,  Global Steps : 26000 )\n",
      "27           1.363\n",
      "                   ( Result : 36.30388,  Loss : 0.0,  Epsilon : 0.71111,  Steps : 1000,  Global Steps : 27000 )\n",
      "28           1.075\n",
      "                   ( Result : -6.71373,  Loss : 0.0,  Epsilon : 0.7033,  Steps : 1000,  Global Steps : 28000 )\n",
      "29           0.829\n",
      "                   ( Result : -6.0647,  Loss : 0.0,  Epsilon : 0.69565,  Steps : 1000,  Global Steps : 29000 )\n",
      "30           0.044\n",
      "                   ( Result : -22.71522,  Loss : 0.0,  Epsilon : 0.68817,  Steps : 1000,  Global Steps : 30000 )\n",
      "31           -0.261\n",
      "                   ( Result : -9.4082,  Loss : 0.0,  Epsilon : 0.68085,  Steps : 1000,  Global Steps : 31000 )\n",
      "32           -0.492\n",
      "                   ( Result : -7.65713,  Loss : 0.0,  Epsilon : 0.67368,  Steps : 1000,  Global Steps : 32000 )\n",
      "33           -0.206\n",
      "                   ( Result : 8.93685,  Loss : 0.0,  Epsilon : 0.66667,  Steps : 1000,  Global Steps : 33000 )\n",
      "34           -0.768\n",
      "                   ( Result : -19.28534,  Loss : 0.0,  Epsilon : 0.65979,  Steps : 1000,  Global Steps : 34000 )\n",
      "35           -0.91\n",
      "                   ( Result : -5.77,  Loss : 0.0,  Epsilon : 0.65306,  Steps : 1000,  Global Steps : 35000 )\n",
      "36           -0.821\n",
      "                   ( Result : 2.31504,  Loss : 0.0,  Epsilon : 0.64646,  Steps : 1000,  Global Steps : 36000 )\n",
      "37           -1.551\n",
      "                   ( Result : -27.81873,  Loss : 0.0,  Epsilon : 0.64,  Steps : 1000,  Global Steps : 37000 )\n",
      "38           -1.735\n",
      "                   ( Result : -8.56549,  Loss : 0.0,  Epsilon : 0.63366,  Steps : 1000,  Global Steps : 38000 )\n",
      "39           -1.967\n",
      "                   ( Result : -10.79266,  Loss : 0.0,  Epsilon : 0.62745,  Steps : 1000,  Global Steps : 39000 )\n",
      "40           -1.839\n",
      "                   ( Result : 3.17212,  Loss : 0.0,  Epsilon : 0.62136,  Steps : 1000,  Global Steps : 40000 )\n",
      "41           -1.93\n",
      "                   ( Result : -5.56746,  Loss : 0.0,  Epsilon : 0.61538,  Steps : 1000,  Global Steps : 41000 )\n",
      "42           -1.434\n",
      "                   ( Result : 18.88794,  Loss : 0.0,  Epsilon : 0.60952,  Steps : 1000,  Global Steps : 42000 )\n",
      "43           -1.63\n",
      "                   ( Result : -9.8534,  Loss : 0.0,  Epsilon : 0.60377,  Steps : 1000,  Global Steps : 43000 )\n",
      "44           -1.89\n",
      "                   ( Result : -13.08495,  Loss : 0.0,  Epsilon : 0.59813,  Steps : 1000,  Global Steps : 44000 )\n",
      "45           -1.632\n",
      "                   ( Result : 9.73473,  Loss : 0.0,  Epsilon : 0.59259,  Steps : 1000,  Global Steps : 45000 )\n",
      "46           -1.494\n",
      "                   ( Result : 4.72586,  Loss : 0.0,  Epsilon : 0.58716,  Steps : 1000,  Global Steps : 46000 )\n",
      "47           -1.522\n",
      "                   ( Result : -2.84274,  Loss : 0.0,  Epsilon : 0.58182,  Steps : 1000,  Global Steps : 47000 )\n",
      "48           -1.194\n",
      "                   ( Result : 14.24454,  Loss : 0.0,  Epsilon : 0.57658,  Steps : 1000,  Global Steps : 48000 )\n",
      "49           -1.078\n",
      "                   ( Result : 4.46592,  Loss : 0.0,  Epsilon : 0.57143,  Steps : 1000,  Global Steps : 49000 )\n",
      "50           -0.575\n",
      "                   ( Result : 24.08317,  Loss : 0.0,  Epsilon : 0.56637,  Steps : 1000,  Global Steps : 50000 )\n",
      "51           -0.202\n",
      "                   ( Result : 18.45122,  Loss : 0.0,  Epsilon : 0.5614,  Steps : 1000,  Global Steps : 51000 )\n",
      "52           0.258\n",
      "                   ( Result : 23.70643,  Loss : 0.0,  Epsilon : 0.55652,  Steps : 1000,  Global Steps : 52000 )\n",
      "53           0.489\n",
      "                   ( Result : 12.49418,  Loss : 0.0,  Epsilon : 0.55172,  Steps : 1000,  Global Steps : 53000 )\n",
      "54           0.432\n",
      "                   ( Result : -2.5706,  Loss : 0.0,  Epsilon : 0.54701,  Steps : 1000,  Global Steps : 54000 )\n",
      "55           0.558\n",
      "                   ( Result : 7.37939,  Loss : 0.0,  Epsilon : 0.54237,  Steps : 1000,  Global Steps : 55000 )\n",
      "56           0.779\n",
      "                   ( Result : 12.911,  Loss : 0.0,  Epsilon : 0.53782,  Steps : 1000,  Global Steps : 56000 )\n",
      "57           0.85\n",
      "                   ( Result : 4.83771,  Loss : 0.0,  Epsilon : 0.53333,  Steps : 1000,  Global Steps : 57000 )\n",
      "58           1.062\n",
      "                   ( Result : 13.15908,  Loss : 0.0,  Epsilon : 0.52893,  Steps : 1000,  Global Steps : 58000 )\n",
      "59           1.454\n",
      "                   ( Result : 24.15807,  Loss : 0.0,  Epsilon : 0.52459,  Steps : 1000,  Global Steps : 59000 )\n",
      "60           1.555\n",
      "                   ( Result : 7.56085,  Loss : 0.0,  Epsilon : 0.52033,  Steps : 1000,  Global Steps : 60000 )\n",
      "61           1.525\n",
      "                   ( Result : -0.27895,  Loss : 0.0,  Epsilon : 0.51613,  Steps : 1000,  Global Steps : 61000 )\n",
      "62           1.314\n",
      "                   ( Result : -11.56004,  Loss : 0.0,  Epsilon : 0.512,  Steps : 1000,  Global Steps : 62000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63           1.428\n",
      "                   ( Result : 8.46838,  Loss : 0.0,  Epsilon : 0.50794,  Steps : 1000,  Global Steps : 63000 )\n",
      "64           1.079\n",
      "                   ( Result : -20.87561,  Loss : 0.0,  Epsilon : 0.50394,  Steps : 1000,  Global Steps : 64000 )\n",
      "65           1.204\n",
      "                   ( Result : 9.16566,  Loss : 0.0,  Epsilon : 0.5,  Steps : 1000,  Global Steps : 65000 )\n",
      "66           0.994\n",
      "                   ( Result : -12.65279,  Loss : 0.0,  Epsilon : 0.49612,  Steps : 1000,  Global Steps : 66000 )\n",
      "67           0.821\n",
      "                   ( Result : -10.57713,  Loss : 0.0,  Epsilon : 0.49231,  Steps : 1000,  Global Steps : 67000 )\n",
      "68           1.095\n",
      "                   ( Result : 19.47227,  Loss : 0.0,  Epsilon : 0.48855,  Steps : 1000,  Global Steps : 68000 )\n",
      "69           0.962\n",
      "                   ( Result : -8.12419,  Loss : 0.0,  Epsilon : 0.48485,  Steps : 1000,  Global Steps : 69000 )\n",
      "70           1.01\n",
      "                   ( Result : 4.33888,  Loss : 0.0,  Epsilon : 0.4812,  Steps : 1000,  Global Steps : 70000 )\n",
      "71           1.251\n",
      "                   ( Result : 18.12453,  Loss : 0.0,  Epsilon : 0.47761,  Steps : 1000,  Global Steps : 71000 )\n",
      "72           1.11\n",
      "                   ( Result : -8.87922,  Loss : 0.0,  Epsilon : 0.47407,  Steps : 1000,  Global Steps : 72000 )\n",
      "73           0.969\n",
      "                   ( Result : -9.21969,  Loss : 0.0,  Epsilon : 0.47059,  Steps : 1000,  Global Steps : 73000 )\n",
      "74           0.935\n",
      "                   ( Result : -1.52592,  Loss : 0.0,  Epsilon : 0.46715,  Steps : 1000,  Global Steps : 74000 )\n",
      "75           0.818\n",
      "                   ( Result : -7.81726,  Loss : 0.0,  Epsilon : 0.46377,  Steps : 1000,  Global Steps : 75000 )\n",
      "76           0.517\n",
      "                   ( Result : -22.05809,  Loss : 0.0,  Epsilon : 0.46043,  Steps : 1000,  Global Steps : 76000 )\n",
      "77           0.6\n",
      "                   ( Result : 6.85617,  Loss : 0.0,  Epsilon : 0.45714,  Steps : 1000,  Global Steps : 77000 )\n",
      "78           0.417\n",
      "                   ( Result : -13.65746,  Loss : 0.0,  Epsilon : 0.4539,  Steps : 1000,  Global Steps : 78000 )\n",
      "79           0.281\n",
      "                   ( Result : -10.29298,  Loss : 0.0,  Epsilon : 0.4507,  Steps : 1000,  Global Steps : 79000 )\n",
      "80           0.535\n",
      "                   ( Result : 20.57098,  Loss : 0.0,  Epsilon : 0.44755,  Steps : 1000,  Global Steps : 80000 )\n",
      "81           0.54\n",
      "                   ( Result : 0.90035,  Loss : 0.0,  Epsilon : 0.44444,  Steps : 1000,  Global Steps : 81000 )\n",
      "82           0.288\n",
      "                   ( Result : -20.05401,  Loss : 0.0,  Epsilon : 0.44138,  Steps : 1000,  Global Steps : 82000 )\n",
      "83           0.216\n",
      "                   ( Result : -5.76125,  Loss : 0.0,  Epsilon : 0.43836,  Steps : 1000,  Global Steps : 83000 )\n",
      "84           0.49\n",
      "                   ( Result : 23.25319,  Loss : 0.0,  Epsilon : 0.43537,  Steps : 1000,  Global Steps : 84000 )\n",
      "85           0.665\n",
      "                   ( Result : 15.38597,  Loss : 0.0,  Epsilon : 0.43243,  Steps : 1000,  Global Steps : 85000 )\n",
      "86           0.476\n",
      "                   ( Result : -15.59773,  Loss : 0.0,  Epsilon : 0.42953,  Steps : 1000,  Global Steps : 86000 )\n",
      "87           0.395\n",
      "                   ( Result : -6.60573,  Loss : 0.0,  Epsilon : 0.42667,  Steps : 1000,  Global Steps : 87000 )\n",
      "88           0.666\n",
      "                   ( Result : 24.25464,  Loss : 0.0,  Epsilon : 0.42384,  Steps : 1000,  Global Steps : 88000 )\n",
      "89           0.426\n",
      "                   ( Result : -20.6422,  Loss : 0.0,  Epsilon : 0.42105,  Steps : 1000,  Global Steps : 89000 )\n",
      "90           0.223\n",
      "                   ( Result : -17.87213,  Loss : 0.0,  Epsilon : 0.4183,  Steps : 1000,  Global Steps : 90000 )\n",
      "91           0.535\n",
      "                   ( Result : 28.64075,  Loss : 0.0,  Epsilon : 0.41558,  Steps : 1000,  Global Steps : 91000 )\n",
      "92           0.76\n",
      "                   ( Result : 21.17685,  Loss : 0.0,  Epsilon : 0.4129,  Steps : 1000,  Global Steps : 92000 )\n",
      "93           0.78\n",
      "                   ( Result : 2.62358,  Loss : 0.0,  Epsilon : 0.41026,  Steps : 1000,  Global Steps : 93000 )\n",
      "94           0.59\n",
      "                   ( Result : -17.04144,  Loss : 0.0,  Epsilon : 0.40764,  Steps : 1000,  Global Steps : 94000 )\n",
      "95           0.411\n",
      "                   ( Result : -16.4608,  Loss : 0.0,  Epsilon : 0.40506,  Steps : 1000,  Global Steps : 95000 )\n",
      "96           0.305\n",
      "                   ( Result : -9.68056,  Loss : 0.0,  Epsilon : 0.40252,  Steps : 1000,  Global Steps : 96000 )\n",
      "97           0.168\n",
      "                   ( Result : -13.05025,  Loss : 0.0,  Epsilon : 0.4,  Steps : 1000,  Global Steps : 97000 )\n",
      "98           0.588\n",
      "                   ( Result : 41.3516,  Loss : 0.0,  Epsilon : 0.39752,  Steps : 1000,  Global Steps : 98000 )\n",
      "99           0.886\n",
      "                   ( Result : 30.09642,  Loss : 0.0,  Epsilon : 0.39506,  Steps : 1000,  Global Steps : 99000 )\n",
      "100           1.124\n",
      "                   ( Result : 24.69967,  Loss : 0.0,  Epsilon : 0.39264,  Steps : 1000,  Global Steps : 100000 )\n",
      "101           1.513\n",
      "                   ( Result : 36.86824,  Loss : 0.0,  Epsilon : 0.39024,  Steps : 1000,  Global Steps : 101000 )\n",
      "102           1.78\n",
      "                   ( Result : 39.71303,  Loss : 0.0,  Epsilon : 0.38788,  Steps : 1000,  Global Steps : 102000 )\n",
      "103           1.987\n",
      "                   ( Result : 16.39213,  Loss : 0.0,  Epsilon : 0.38554,  Steps : 1000,  Global Steps : 103000 )\n",
      "104           2.212\n",
      "                   ( Result : 20.98129,  Loss : 0.0,  Epsilon : 0.38323,  Steps : 1000,  Global Steps : 104000 )\n",
      "105           2.211\n",
      "                   ( Result : -0.78935,  Loss : 0.0,  Epsilon : 0.38095,  Steps : 1000,  Global Steps : 105000 )\n",
      "106           2.446\n",
      "                   ( Result : 9.16008,  Loss : 0.0,  Epsilon : 0.3787,  Steps : 1000,  Global Steps : 106000 )\n",
      "107           2.536\n",
      "                   ( Result : -12.96448,  Loss : 0.0,  Epsilon : 0.37647,  Steps : 1000,  Global Steps : 107000 )\n",
      "108           2.705\n",
      "                   ( Result : -0.01243,  Loss : 0.0,  Epsilon : 0.37427,  Steps : 1000,  Global Steps : 108000 )\n",
      "109           2.77\n",
      "                   ( Result : 6.07814,  Loss : 0.0,  Epsilon : 0.37209,  Steps : 1000,  Global Steps : 109000 )\n",
      "110           2.89\n",
      "                   ( Result : 14.6268,  Loss : 0.0,  Epsilon : 0.36994,  Steps : 1000,  Global Steps : 110000 )\n",
      "111           2.862\n",
      "                   ( Result : -3.52515,  Loss : 0.0,  Epsilon : 0.36782,  Steps : 1000,  Global Steps : 111000 )\n",
      "112           2.927\n",
      "                   ( Result : 21.06824,  Loss : 0.0,  Epsilon : 0.36571,  Steps : 1000,  Global Steps : 112000 )\n",
      "113           2.886\n",
      "                   ( Result : -8.66651,  Loss : 0.0,  Epsilon : 0.36364,  Steps : 1000,  Global Steps : 113000 )\n",
      "114           2.841\n",
      "                   ( Result : -6.88898,  Loss : 0.0,  Epsilon : 0.36158,  Steps : 1000,  Global Steps : 114000 )\n",
      "115           2.615\n",
      "                   ( Result : -4.92909,  Loss : 0.0,  Epsilon : 0.35955,  Steps : 1000,  Global Steps : 115000 )\n",
      "116           2.804\n",
      "                   ( Result : 17.24411,  Loss : 0.0,  Epsilon : 0.35754,  Steps : 1000,  Global Steps : 116000 )\n",
      "117           3.21\n",
      "                   ( Result : 43.28221,  Loss : 0.0,  Epsilon : 0.35556,  Steps : 1000,  Global Steps : 117000 )\n",
      "118           2.955\n",
      "                   ( Result : 6.02282,  Loss : 0.0,  Epsilon : 0.35359,  Steps : 1000,  Global Steps : 118000 )\n",
      "119           3.39\n",
      "                   ( Result : 27.74078,  Loss : 0.0,  Epsilon : 0.35165,  Steps : 1000,  Global Steps : 119000 )\n",
      "120           2.823\n",
      "                   ( Result : -6.66832,  Loss : 0.0,  Epsilon : 0.34973,  Steps : 1000,  Global Steps : 120000 )\n",
      "121           2.924\n",
      "                   ( Result : -0.99208,  Loss : 0.0,  Epsilon : 0.34783,  Steps : 1000,  Global Steps : 121000 )\n",
      "122           2.614\n",
      "                   ( Result : -28.92004,  Loss : 0.0,  Epsilon : 0.34595,  Steps : 1000,  Global Steps : 122000 )\n",
      "123           2.961\n",
      "                   ( Result : 14.99679,  Loss : 0.0,  Epsilon : 0.34409,  Steps : 1000,  Global Steps : 123000 )\n",
      "124           2.894\n",
      "                   ( Result : -10.05274,  Loss : 0.0,  Epsilon : 0.34225,  Steps : 1000,  Global Steps : 124000 )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-56782d3621a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                       \u001b[0mGame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Swimmer-v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Swimmer_E+S+SP_test1(1024,1,10,64,0.0001)_seed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                       \u001b[0mExp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExp_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                       Double = Double_list[i], Dueling = Dueling_list[i], Prioritized = False)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jolp/Reinforcement Learning/Epsilon_NEW/Strategy.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, dis, REPLAY_MEMORY, batch_size, max_episodes, layer_size_Q1, layer_size_Q2, learning_rate_Q, training_step, copy_step, repu_num, action_res, ending_cond_epis, ending_cond_reward, alpha, beta_init, eps, eps_div, Double, Dueling, Prioritized, Exp, seed_n, Game, file_name, case_n, save_epi)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mending_cond_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mending_cond_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_DDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDouble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDouble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDueling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDueling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrioritized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrioritized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jolp/Reinforcement Learning/Epsilon_NEW/Strategy.pyc\u001b[0m in \u001b[0;36mrun_DDPG\u001b[0;34m(self, case_n, seed_n, Exp, Double, Dueling, Prioritized)\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                         \u001b[0mq_t_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                         \u001b[0mq_t_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mq_t_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jolp/Reinforcement Learning/Epsilon_NEW/Train.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(Q_Network, train_batch, Exp, input_size, num_actions)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstate_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstate_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mstate_t_1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstate_t_1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_t_1_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Strategy import RL\n",
    "\n",
    "case_num = 3\n",
    "\n",
    "# 1 : epsilon , 2 : softmax , 3 : sparsemax\n",
    "Exp_list = ['epsilon', 'softmax', 'sparsemax']\n",
    "\n",
    "Double_list = [True, True, True]\n",
    "Dueling_list = [True, True, True]\n",
    "Prioritized_list = [True, True, True]\n",
    "\n",
    "action_res_list = [51, 51]\n",
    "\n",
    "\n",
    "t_list = [100, 100, 200]\n",
    "c_list = [500, 1000, 1000]\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "for i in range(case_num):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Session(config=config) as sess :\n",
    "        \n",
    "        CartPole = RL(sess, dis = 0.99, REPLAY_MEMORY = 100000, max_episodes = 2000, action_res = action_res_list,\n",
    "                      \n",
    "                      batch_size = 1024, training_step = 1, copy_step = 10,\n",
    "                      eps_div = 64, repu_num = 1,\n",
    "                      layer_size_Q1 = 512, layer_size_Q2 = 256, learning_rate_Q = 0.0001,\n",
    "                      \n",
    "                      alpha = 0.6, beta_init = 0.4, eps = 0.01, save_epi = 10000,\n",
    "                      ending_cond_epis = 100, ending_cond_reward = 480,\n",
    "                      \n",
    "                      Game = 'Swimmer-v1', file_name = 'Swimmer_E+S+SP_test1(1024,1,10,64,0.0001)_seed',\n",
    "                      Exp = Exp_list[i], case_n = i+1, seed_n = i,\n",
    "                      Double = Double_list[i], Dueling = Dueling_list[i], Prioritized = False)\n",
    "    \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
