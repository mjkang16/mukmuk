{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "[2018-03-06 01:32:53,944] Making new env: Swimmer-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-03-06 01:32:54,600] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CASE 1\n",
      "  Exp : DDPG\n",
      "  STATE DIM : 8, ACTION DIM : 2\n",
      "1           14.831\n",
      "                   ( Result : 14.83096,  Loss : 0.0,  Steps : 1000,  Global Steps : 1000 )\n",
      "2           18.197\n",
      "                   ( Result : 21.56212,  Loss : 0.0,  Steps : 1000,  Global Steps : 2000 )\n",
      "3           20.021\n",
      "                   ( Result : 23.66889,  Loss : 0.0,  Steps : 1000,  Global Steps : 3000 )\n",
      "4           16.427\n",
      "                   ( Result : 5.64417,  Loss : 0.0,  Steps : 1000,  Global Steps : 4000 )\n",
      "5           16.87\n",
      "                   ( Result : 18.64552,  Loss : 0.0,  Steps : 1000,  Global Steps : 5000 )\n",
      "6           15.364\n",
      "                   ( Result : 7.83145,  Loss : 0.0,  Steps : 1000,  Global Steps : 6000 )\n",
      "7           13.67\n",
      "                   ( Result : 3.50849,  Loss : 0.0,  Steps : 1000,  Global Steps : 7000 )\n",
      "8           12.733\n",
      "                   ( Result : 6.16902,  Loss : 0.0,  Steps : 1000,  Global Steps : 8000 )\n",
      "9           13.163\n",
      "                   ( Result : 16.60635,  Loss : 0.0,  Steps : 1000,  Global Steps : 9000 )\n",
      "10           13.918\n",
      "                   ( Result : 20.71364,  Loss : 0.0,  Steps : 1000,  Global Steps : 10000 )\n",
      "11           13.166\n",
      "                   ( Result : 5.63998,  Loss : 0.0,  Steps : 1000,  Global Steps : 11000 )\n",
      "12           12.798\n",
      "                   ( Result : 8.752,  Loss : 0.0,  Steps : 1000,  Global Steps : 12000 )\n",
      "13           14.157\n",
      "                   ( Result : 30.46267,  Loss : 0.0,  Steps : 1000,  Global Steps : 13000 )\n",
      "14           14.535\n",
      "                   ( Result : 19.45787,  Loss : 0.0,  Steps : 1000,  Global Steps : 14000 )\n",
      "15           13.608\n",
      "                   ( Result : 0.62165,  Loss : 0.0,  Steps : 1000,  Global Steps : 15000 )\n",
      "16           13.356\n",
      "                   ( Result : 9.57887,  Loss : 0.0,  Steps : 1000,  Global Steps : 16000 )\n",
      "17           12.543\n",
      "                   ( Result : -0.47033,  Loss : 0.0,  Steps : 1000,  Global Steps : 17000 )\n",
      "18           12.973\n",
      "                   ( Result : 20.28893,  Loss : 0.0,  Steps : 1000,  Global Steps : 18000 )\n",
      "19           12.97\n",
      "                   ( Result : 12.91592,  Loss : 0.0,  Steps : 1000,  Global Steps : 19000 )\n",
      "20           12.949\n",
      "                   ( Result : 12.54191,  Loss : 0.0,  Steps : 1000,  Global Steps : 20000 )\n",
      "21           12.798\n",
      "                   ( Result : 9.78637,  Loss : 0.0,  Steps : 1000,  Global Steps : 21000 )\n",
      "22           12.808\n",
      "                   ( Result : 13.01233,  Loss : 0.0,  Steps : 1000,  Global Steps : 22000 )\n",
      "23           13.262\n",
      "                   ( Result : 23.26335,  Loss : 0.0,  Steps : 1000,  Global Steps : 23000 )\n",
      "24           13.749\n",
      "                   ( Result : 24.95581,  Loss : 0.0,  Steps : 1000,  Global Steps : 24000 )\n",
      "25           13.554\n",
      "                   ( Result : 8.85282,  Loss : 0.0,  Steps : 1000,  Global Steps : 25000 )\n",
      "26           13.373\n",
      "                   ( Result : 8.85601,  Loss : 0.0,  Steps : 1000,  Global Steps : 26000 )\n",
      "27           13.616\n",
      "                   ( Result : 19.93651,  Loss : 0.0,  Steps : 1000,  Global Steps : 27000 )\n",
      "28           13.989\n",
      "                   ( Result : 24.05318,  Loss : 0.0,  Steps : 1000,  Global Steps : 28000 )\n",
      "29           14.172\n",
      "                   ( Result : 19.28867,  Loss : 0.0,  Steps : 1000,  Global Steps : 29000 )\n",
      "30           14.214\n",
      "                   ( Result : 15.44408,  Loss : 0.0,  Steps : 1000,  Global Steps : 30000 )\n",
      "31           14.405\n",
      "                   ( Result : 20.14813,  Loss : 0.0,  Steps : 1000,  Global Steps : 31000 )\n",
      "32           14.288\n",
      "                   ( Result : 10.6446,  Loss : 0.0,  Steps : 1000,  Global Steps : 32000 )\n",
      "33           13.791\n",
      "                   ( Result : -2.09295,  Loss : 0.0,  Steps : 1000,  Global Steps : 33000 )\n",
      "34           13.259\n",
      "                   ( Result : -4.31104,  Loss : 0.0,  Steps : 1000,  Global Steps : 34000 )\n",
      "35           13.017\n",
      "                   ( Result : 4.79234,  Loss : 0.0,  Steps : 1000,  Global Steps : 35000 )\n",
      "36           13.197\n",
      "                   ( Result : 19.47988,  Loss : 0.0,  Steps : 1000,  Global Steps : 36000 )\n",
      "37           13.146\n",
      "                   ( Result : 11.32651,  Loss : 0.0,  Steps : 1000,  Global Steps : 37000 )\n",
      "38           13.015\n",
      "                   ( Result : 8.17548,  Loss : 0.0,  Steps : 1000,  Global Steps : 38000 )\n",
      "39           13.2\n",
      "                   ( Result : 20.22386,  Loss : 0.0,  Steps : 1000,  Global Steps : 39000 )\n",
      "40           13.598\n",
      "                   ( Result : 29.1294,  Loss : 0.0,  Steps : 1000,  Global Steps : 40000 )\n",
      "41           13.585\n",
      "                   ( Result : 13.0663,  Loss : 0.0,  Steps : 1000,  Global Steps : 41000 )\n",
      "42           13.877\n",
      "                   ( Result : 25.85314,  Loss : 0.0,  Steps : 1000,  Global Steps : 42000 )\n",
      "43           13.541\n",
      "                   ( Result : -0.60796,  Loss : 0.0,  Steps : 1000,  Global Steps : 43000 )\n",
      "44           13.201\n",
      "                   ( Result : -1.39387,  Loss : 0.0,  Steps : 1000,  Global Steps : 44000 )\n",
      "45           13.391\n",
      "                   ( Result : 21.72433,  Loss : 0.0,  Steps : 1000,  Global Steps : 45000 )\n",
      "46           13.548\n",
      "                   ( Result : 20.62199,  Loss : 0.0,  Steps : 1000,  Global Steps : 46000 )\n",
      "47           13.699\n",
      "                   ( Result : 20.66126,  Loss : 0.0,  Steps : 1000,  Global Steps : 47000 )\n",
      "48           13.715\n",
      "                   ( Result : 14.47816,  Loss : 0.0,  Steps : 1000,  Global Steps : 48000 )\n",
      "49           13.446\n",
      "                   ( Result : 0.49107,  Loss : 0.0,  Steps : 1000,  Global Steps : 49000 )\n",
      "50           13.787\n",
      "                   ( Result : 30.49843,  Loss : 0.0,  Steps : 1000,  Global Steps : 50000 )\n",
      "51           13.765\n",
      "                   ( Result : 12.68952,  Loss : 0.0,  Steps : 1000,  Global Steps : 51000 )\n",
      "52           13.773\n",
      "                   ( Result : 14.18614,  Loss : 0.0,  Steps : 1000,  Global Steps : 52000 )\n",
      "53           13.821\n",
      "                   ( Result : 16.30914,  Loss : 0.0,  Steps : 1000,  Global Steps : 53000 )\n",
      "54           13.784\n",
      "                   ( Result : 11.80252,  Loss : 0.0,  Steps : 1000,  Global Steps : 54000 )\n",
      "55           13.943\n",
      "                   ( Result : 22.57113,  Loss : 0.0,  Steps : 1000,  Global Steps : 55000 )\n",
      "56           14.1\n",
      "                   ( Result : 22.71121,  Loss : 0.0,  Steps : 1000,  Global Steps : 56000 )\n",
      "57           14.143\n",
      "                   ( Result : 16.57646,  Loss : 0.0,  Steps : 1000,  Global Steps : 57000 )\n",
      "58           13.849\n",
      "                   ( Result : -2.91501,  Loss : 0.0,  Steps : 1000,  Global Steps : 58000 )\n",
      "59           13.536\n",
      "                   ( Result : -4.63792,  Loss : 0.0,  Steps : 1000,  Global Steps : 59000 )\n",
      "60           13.106\n",
      "                   ( Result : -12.27887,  Loss : 0.0,  Steps : 1000,  Global Steps : 60000 )\n",
      "61           12.614\n",
      "                   ( Result : -16.88014,  Loss : 0.0,  Steps : 1000,  Global Steps : 61000 )\n",
      "62           12.134\n",
      "                   ( Result : -17.18393,  Loss : 0.0,  Steps : 1000,  Global Steps : 62000 )\n",
      "63           11.646\n",
      "                   ( Result : -18.61157,  Loss : 0.0,  Steps : 1000,  Global Steps : 63000 )\n",
      "64           11.11\n",
      "                   ( Result : -22.65523,  Loss : 0.0,  Steps : 1000,  Global Steps : 64000 )\n",
      "65           10.585\n",
      "                   ( Result : -22.99935,  Loss : 0.0,  Steps : 1000,  Global Steps : 65000 )\n",
      "66           10.243\n",
      "                   ( Result : -11.94463,  Loss : 0.0,  Steps : 1000,  Global Steps : 66000 )\n",
      "67           9.766\n",
      "                   ( Result : -21.7746,  Loss : 0.0,  Steps : 1000,  Global Steps : 67000 )\n",
      "68           9.293\n",
      "                   ( Result : -22.35169,  Loss : 0.0,  Steps : 1000,  Global Steps : 68000 )\n",
      "69           8.974\n",
      "                   ( Result : -12.73687,  Loss : 0.0,  Steps : 1000,  Global Steps : 69000 )\n",
      "70           8.647\n",
      "                   ( Result : -13.93742,  Loss : 0.0,  Steps : 1000,  Global Steps : 70000 )\n",
      "71           8.383\n",
      "                   ( Result : -10.07703,  Loss : 0.0,  Steps : 1000,  Global Steps : 71000 )\n",
      "72           8.106\n",
      "                   ( Result : -11.56057,  Loss : 0.0,  Steps : 1000,  Global Steps : 72000 )\n",
      "73           7.826\n",
      "                   ( Result : -12.33687,  Loss : 0.0,  Steps : 1000,  Global Steps : 73000 )\n",
      "74           7.47\n",
      "                   ( Result : -18.49642,  Loss : 0.0,  Steps : 1000,  Global Steps : 74000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75           7.118\n",
      "                   ( Result : -18.93756,  Loss : 0.0,  Steps : 1000,  Global Steps : 75000 )\n",
      "76           6.84\n",
      "                   ( Result : -14.02363,  Loss : 0.0,  Steps : 1000,  Global Steps : 76000 )\n",
      "77           6.762\n",
      "                   ( Result : 0.87633,  Loss : 0.0,  Steps : 1000,  Global Steps : 77000 )\n",
      "78           6.559\n",
      "                   ( Result : -9.09367,  Loss : 0.0,  Steps : 1000,  Global Steps : 78000 )\n",
      "79           6.532\n",
      "                   ( Result : 4.40294,  Loss : 0.0,  Steps : 1000,  Global Steps : 79000 )\n",
      "80           6.917\n",
      "                   ( Result : 37.37751,  Loss : 0.0,  Steps : 1000,  Global Steps : 80000 )\n",
      "81           7.107\n",
      "                   ( Result : 22.2539,  Loss : 0.0,  Steps : 1000,  Global Steps : 81000 )\n",
      "82           7.259\n",
      "                   ( Result : 19.61882,  Loss : 0.0,  Steps : 1000,  Global Steps : 82000 )\n",
      "83           7.427\n",
      "                   ( Result : 21.19224,  Loss : 0.0,  Steps : 1000,  Global Steps : 83000 )\n",
      "84           7.584\n",
      "                   ( Result : 20.56778,  Loss : 0.0,  Steps : 1000,  Global Steps : 84000 )\n",
      "85           7.762\n",
      "                   ( Result : 22.77326,  Loss : 0.0,  Steps : 1000,  Global Steps : 85000 )\n",
      "86           7.932\n",
      "                   ( Result : 22.36474,  Loss : 0.0,  Steps : 1000,  Global Steps : 86000 )\n",
      "87           8.089\n",
      "                   ( Result : 21.57417,  Loss : 0.0,  Steps : 1000,  Global Steps : 87000 )\n",
      "88           8.22\n",
      "                   ( Result : 19.59896,  Loss : 0.0,  Steps : 1000,  Global Steps : 88000 )\n",
      "89           8.242\n",
      "                   ( Result : 10.19769,  Loss : 0.0,  Steps : 1000,  Global Steps : 89000 )\n",
      "90           8.374\n",
      "                   ( Result : 20.13571,  Loss : 0.0,  Steps : 1000,  Global Steps : 90000 )\n",
      "91           8.554\n",
      "                   ( Result : 24.71096,  Loss : 0.0,  Steps : 1000,  Global Steps : 91000 )\n",
      "92           8.529\n",
      "                   ( Result : 6.24633,  Loss : 0.0,  Steps : 1000,  Global Steps : 92000 )\n",
      "93           8.529\n",
      "                   ( Result : 8.60219,  Loss : 0.0,  Steps : 1000,  Global Steps : 93000 )\n",
      "94           8.472\n",
      "                   ( Result : 3.14723,  Loss : 0.0,  Steps : 1000,  Global Steps : 94000 )\n",
      "95           8.595\n",
      "                   ( Result : 20.17039,  Loss : 0.0,  Steps : 1000,  Global Steps : 95000 )\n",
      "96           8.552\n",
      "                   ( Result : 4.40145,  Loss : 0.0,  Steps : 1000,  Global Steps : 96000 )\n",
      "97           8.601\n",
      "                   ( Result : 13.29687,  Loss : 0.0,  Steps : 1000,  Global Steps : 97000 )\n",
      "98           8.71\n",
      "                   ( Result : 19.37286,  Loss : 0.0,  Steps : 1000,  Global Steps : 98000 )\n",
      "99           8.617\n",
      "                   ( Result : -0.54644,  Loss : 0.0,  Steps : 1000,  Global Steps : 99000 )\n",
      "100           8.561\n",
      "                   ( Result : 3.07091,  Loss : 0.0,  Steps : 1000,  Global Steps : 100000 )\n",
      "101           8.667\n",
      "                   ( Result : 25.4066,  Loss : 0.0,  Steps : 1000,  Global Steps : 101000 )\n",
      "102           8.626\n",
      "                   ( Result : 17.47312,  Loss : 0.0,  Steps : 1000,  Global Steps : 102000 )\n",
      "103           8.51\n",
      "                   ( Result : 11.98846,  Loss : 0.0,  Steps : 1000,  Global Steps : 103000 )\n",
      "104           8.496\n",
      "                   ( Result : 4.25187,  Loss : 0.0,  Steps : 1000,  Global Steps : 104000 )\n",
      "105           8.548\n",
      "                   ( Result : 23.91738,  Loss : 0.0,  Steps : 1000,  Global Steps : 105000 )\n",
      "106           8.729\n",
      "                   ( Result : 25.89786,  Loss : 0.0,  Steps : 1000,  Global Steps : 106000 )\n",
      "107           9.02\n",
      "                   ( Result : 32.63546,  Loss : 0.0,  Steps : 1000,  Global Steps : 107000 )\n",
      "108           9.127\n",
      "                   ( Result : 16.88362,  Loss : 0.0,  Steps : 1000,  Global Steps : 108000 )\n",
      "109           9.137\n",
      "                   ( Result : 17.56871,  Loss : 0.0,  Steps : 1000,  Global Steps : 109000 )\n",
      "110           9.124\n",
      "                   ( Result : 19.40214,  Loss : 0.0,  Steps : 1000,  Global Steps : 110000 )\n",
      "111           9.188\n",
      "                   ( Result : 12.05201,  Loss : 0.0,  Steps : 1000,  Global Steps : 111000 )\n",
      "112           9.155\n",
      "                   ( Result : 5.42473,  Loss : 0.0,  Steps : 1000,  Global Steps : 112000 )\n",
      "113           9.044\n",
      "                   ( Result : 19.43159,  Loss : 0.0,  Steps : 1000,  Global Steps : 113000 )\n",
      "114           8.908\n",
      "                   ( Result : 5.85453,  Loss : 0.0,  Steps : 1000,  Global Steps : 114000 )\n",
      "115           9.083\n",
      "                   ( Result : 18.06436,  Loss : 0.0,  Steps : 1000,  Global Steps : 115000 )\n",
      "116           9.26\n",
      "                   ( Result : 27.32458,  Loss : 0.0,  Steps : 1000,  Global Steps : 116000 )\n",
      "117           9.512\n",
      "                   ( Result : 24.6884,  Loss : 0.0,  Steps : 1000,  Global Steps : 117000 )\n",
      "118           9.434\n",
      "                   ( Result : 12.53661,  Loss : 0.0,  Steps : 1000,  Global Steps : 118000 )\n",
      "119           9.398\n",
      "                   ( Result : 9.27171,  Loss : 0.0,  Steps : 1000,  Global Steps : 119000 )\n",
      "120           9.498\n",
      "                   ( Result : 22.53379,  Loss : 0.0,  Steps : 1000,  Global Steps : 120000 )\n",
      "121           9.48\n",
      "                   ( Result : 7.99098,  Loss : 0.0,  Steps : 1000,  Global Steps : 121000 )\n",
      "122           9.535\n",
      "                   ( Result : 18.54738,  Loss : 0.0,  Steps : 1000,  Global Steps : 122000 )\n",
      "123           9.475\n",
      "                   ( Result : 17.23756,  Loss : 0.0,  Steps : 1000,  Global Steps : 123000 )\n",
      "124           9.388\n",
      "                   ( Result : 16.21925,  Loss : 0.0,  Steps : 1000,  Global Steps : 124000 )\n",
      "125           9.42\n",
      "                   ( Result : 12.13289,  Loss : 0.0,  Steps : 1000,  Global Steps : 125000 )\n",
      "126           9.292\n",
      "                   ( Result : -4.02165,  Loss : 0.0,  Steps : 1000,  Global Steps : 126000 )\n",
      "127           9.292\n",
      "                   ( Result : 20.01866,  Loss : 0.0,  Steps : 1000,  Global Steps : 127000 )\n",
      "128           9.312\n",
      "                   ( Result : 26.02574,  Loss : 0.0,  Steps : 1000,  Global Steps : 128000 )\n",
      "129           9.358\n",
      "                   ( Result : 23.87836,  Loss : 0.0,  Steps : 1000,  Global Steps : 129000 )\n",
      "130           9.285\n",
      "                   ( Result : 8.15205,  Loss : 0.0,  Steps : 1000,  Global Steps : 130000 )\n",
      "131           9.163\n",
      "                   ( Result : 7.91429,  Loss : 0.0,  Steps : 1000,  Global Steps : 131000 )\n",
      "132           9.158\n",
      "                   ( Result : 10.12177,  Loss : 0.0,  Steps : 1000,  Global Steps : 132000 )\n",
      "133           9.339\n",
      "                   ( Result : 16.06659,  Loss : 0.0,  Steps : 1000,  Global Steps : 133000 )\n",
      "134           9.493\n",
      "                   ( Result : 11.04397,  Loss : 0.0,  Steps : 1000,  Global Steps : 134000 )\n",
      "135           9.601\n",
      "                   ( Result : 15.59805,  Loss : 0.0,  Steps : 1000,  Global Steps : 135000 )\n",
      "136           9.658\n",
      "                   ( Result : 25.15511,  Loss : 0.0,  Steps : 1000,  Global Steps : 136000 )\n",
      "137           9.594\n",
      "                   ( Result : 4.9965,  Loss : 0.0,  Steps : 1000,  Global Steps : 137000 )\n",
      "138           9.617\n",
      "                   ( Result : 10.4396,  Loss : 0.0,  Steps : 1000,  Global Steps : 138000 )\n",
      "139           9.57\n",
      "                   ( Result : 15.55171,  Loss : 0.0,  Steps : 1000,  Global Steps : 139000 )\n",
      "140           9.474\n",
      "                   ( Result : 19.52976,  Loss : 0.0,  Steps : 1000,  Global Steps : 140000 )\n",
      "141           9.57\n",
      "                   ( Result : 22.61688,  Loss : 0.0,  Steps : 1000,  Global Steps : 141000 )\n",
      "142           9.51\n",
      "                   ( Result : 19.87442,  Loss : 0.0,  Steps : 1000,  Global Steps : 142000 )\n",
      "143           9.514\n",
      "                   ( Result : -0.16433,  Loss : 0.0,  Steps : 1000,  Global Steps : 143000 )\n",
      "144           9.572\n",
      "                   ( Result : 4.35658,  Loss : 0.0,  Steps : 1000,  Global Steps : 144000 )\n",
      "145           9.501\n",
      "                   ( Result : 14.65579,  Loss : 0.0,  Steps : 1000,  Global Steps : 145000 )\n",
      "146           9.438\n",
      "                   ( Result : 14.30913,  Loss : 0.0,  Steps : 1000,  Global Steps : 146000 )\n",
      "147           9.286\n",
      "                   ( Result : 5.46312,  Loss : 0.0,  Steps : 1000,  Global Steps : 147000 )\n",
      "148           9.271\n",
      "                   ( Result : 12.92726,  Loss : 0.0,  Steps : 1000,  Global Steps : 148000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149           9.471\n",
      "                   ( Result : 20.55409,  Loss : 0.0,  Steps : 1000,  Global Steps : 149000 )\n",
      "150           9.325\n",
      "                   ( Result : 15.85896,  Loss : 0.0,  Steps : 1000,  Global Steps : 150000 )\n",
      "151           9.377\n",
      "                   ( Result : 17.92265,  Loss : 0.0,  Steps : 1000,  Global Steps : 151000 )\n",
      "152           9.384\n",
      "                   ( Result : 14.85344,  Loss : 0.0,  Steps : 1000,  Global Steps : 152000 )\n",
      "153           9.358\n",
      "                   ( Result : 13.68655,  Loss : 0.0,  Steps : 1000,  Global Steps : 153000 )\n",
      "154           9.267\n",
      "                   ( Result : 2.76337,  Loss : 0.0,  Steps : 1000,  Global Steps : 154000 )\n",
      "155           9.299\n",
      "                   ( Result : 25.70969,  Loss : 0.0,  Steps : 1000,  Global Steps : 155000 )\n",
      "156           9.193\n",
      "                   ( Result : 12.18194,  Loss : 0.0,  Steps : 1000,  Global Steps : 156000 )\n",
      "157           9.232\n",
      "                   ( Result : 20.47752,  Loss : 0.0,  Steps : 1000,  Global Steps : 157000 )\n",
      "158           9.521\n",
      "                   ( Result : 25.96085,  Loss : 0.0,  Steps : 1000,  Global Steps : 158000 )\n",
      "159           9.819\n",
      "                   ( Result : 25.12551,  Loss : 0.0,  Steps : 1000,  Global Steps : 159000 )\n",
      "160           10.195\n",
      "                   ( Result : 25.35599,  Loss : 0.0,  Steps : 1000,  Global Steps : 160000 )\n",
      "161           10.551\n",
      "                   ( Result : 18.70358,  Loss : 0.0,  Steps : 1000,  Global Steps : 161000 )\n",
      "162           10.975\n",
      "                   ( Result : 25.2575,  Loss : 0.0,  Steps : 1000,  Global Steps : 162000 )\n",
      "163           11.333\n",
      "                   ( Result : 17.11894,  Loss : 0.0,  Steps : 1000,  Global Steps : 163000 )\n",
      "164           11.617\n",
      "                   ( Result : 5.82167,  Loss : 0.0,  Steps : 1000,  Global Steps : 164000 )\n",
      "165           11.982\n",
      "                   ( Result : 13.48169,  Loss : 0.0,  Steps : 1000,  Global Steps : 165000 )\n",
      "166           12.318\n",
      "                   ( Result : 21.66987,  Loss : 0.0,  Steps : 1000,  Global Steps : 166000 )\n",
      "167           12.557\n",
      "                   ( Result : 2.13331,  Loss : 0.0,  Steps : 1000,  Global Steps : 167000 )\n",
      "168           12.917\n",
      "                   ( Result : 13.60078,  Loss : 0.0,  Steps : 1000,  Global Steps : 168000 )\n",
      "169           13.112\n",
      "                   ( Result : 6.77265,  Loss : 0.0,  Steps : 1000,  Global Steps : 169000 )\n",
      "170           13.503\n",
      "                   ( Result : 25.12106,  Loss : 0.0,  Steps : 1000,  Global Steps : 170000 )\n",
      "171           13.656\n",
      "                   ( Result : 5.29961,  Loss : 0.0,  Steps : 1000,  Global Steps : 171000 )\n",
      "172           13.919\n",
      "                   ( Result : 14.67289,  Loss : 0.0,  Steps : 1000,  Global Steps : 172000 )\n",
      "173           14.255\n",
      "                   ( Result : 21.32067,  Loss : 0.0,  Steps : 1000,  Global Steps : 173000 )\n",
      "174           14.538\n",
      "                   ( Result : 9.74889,  Loss : 0.0,  Steps : 1000,  Global Steps : 174000 )\n",
      "175           14.847\n",
      "                   ( Result : 11.97546,  Loss : 0.0,  Steps : 1000,  Global Steps : 175000 )\n",
      "176           15.071\n",
      "                   ( Result : 8.36525,  Loss : 0.0,  Steps : 1000,  Global Steps : 176000 )\n",
      "177           15.243\n",
      "                   ( Result : 18.10743,  Loss : 0.0,  Steps : 1000,  Global Steps : 177000 )\n",
      "178           15.309\n",
      "                   ( Result : -2.53341,  Loss : 0.0,  Steps : 1000,  Global Steps : 178000 )\n",
      "179           15.464\n",
      "                   ( Result : 19.92676,  Loss : 0.0,  Steps : 1000,  Global Steps : 179000 )\n",
      "180           15.338\n",
      "                   ( Result : 24.75615,  Loss : 0.0,  Steps : 1000,  Global Steps : 180000 )\n",
      "181           15.36\n",
      "                   ( Result : 24.49817,  Loss : 0.0,  Steps : 1000,  Global Steps : 181000 )\n",
      "182           15.316\n",
      "                   ( Result : 15.21087,  Loss : 0.0,  Steps : 1000,  Global Steps : 182000 )\n",
      "183           15.142\n",
      "                   ( Result : 3.74969,  Loss : 0.0,  Steps : 1000,  Global Steps : 183000 )\n",
      "184           15.071\n",
      "                   ( Result : 13.5348,  Loss : 0.0,  Steps : 1000,  Global Steps : 184000 )\n",
      "185           15.005\n",
      "                   ( Result : 16.10328,  Loss : 0.0,  Steps : 1000,  Global Steps : 185000 )\n",
      "186           14.978\n",
      "                   ( Result : 19.68436,  Loss : 0.0,  Steps : 1000,  Global Steps : 186000 )\n",
      "187           14.875\n",
      "                   ( Result : 11.26048,  Loss : 0.0,  Steps : 1000,  Global Steps : 187000 )\n",
      "188           14.806\n",
      "                   ( Result : 12.74056,  Loss : 0.0,  Steps : 1000,  Global Steps : 188000 )\n",
      "189           14.936\n",
      "                   ( Result : 23.18705,  Loss : 0.0,  Steps : 1000,  Global Steps : 189000 )\n",
      "190           14.885\n",
      "                   ( Result : 14.99732,  Loss : 0.0,  Steps : 1000,  Global Steps : 190000 )\n",
      "191           14.819\n",
      "                   ( Result : 18.11863,  Loss : 0.0,  Steps : 1000,  Global Steps : 191000 )\n",
      "192           14.907\n",
      "                   ( Result : 15.06253,  Loss : 0.0,  Steps : 1000,  Global Steps : 192000 )\n",
      "193           14.911\n",
      "                   ( Result : 8.9784,  Loss : 0.0,  Steps : 1000,  Global Steps : 193000 )\n",
      "194           15.012\n",
      "                   ( Result : 13.33802,  Loss : 0.0,  Steps : 1000,  Global Steps : 194000 )\n",
      "195           15.122\n",
      "                   ( Result : 31.17186,  Loss : 0.0,  Steps : 1000,  Global Steps : 195000 )\n",
      "196           15.251\n",
      "                   ( Result : 17.23154,  Loss : 0.0,  Steps : 1000,  Global Steps : 196000 )\n",
      "197           15.19\n",
      "                   ( Result : 7.23255,  Loss : 0.0,  Steps : 1000,  Global Steps : 197000 )\n",
      "198           15.201\n",
      "                   ( Result : 20.44057,  Loss : 0.0,  Steps : 1000,  Global Steps : 198000 )\n",
      "199           15.498\n",
      "                   ( Result : 29.1414,  Loss : 0.0,  Steps : 1000,  Global Steps : 199000 )\n",
      "200           15.647\n",
      "                   ( Result : 17.96937,  Loss : 0.0,  Steps : 1000,  Global Steps : 200000 )\n",
      "201           15.48\n",
      "                   ( Result : 8.74617,  Loss : 0.0,  Steps : 1000,  Global Steps : 201000 )\n",
      "202           15.478\n",
      "                   ( Result : 17.30367,  Loss : 0.0,  Steps : 1000,  Global Steps : 202000 )\n",
      "203           15.379\n",
      "                   ( Result : 2.01098,  Loss : 0.0,  Steps : 1000,  Global Steps : 203000 )\n",
      "204           15.564\n",
      "                   ( Result : 22.76531,  Loss : 0.0,  Steps : 1000,  Global Steps : 204000 )\n",
      "205           15.435\n",
      "                   ( Result : 11.05612,  Loss : 0.0,  Steps : 1000,  Global Steps : 205000 )\n",
      "206           15.422\n",
      "                   ( Result : 24.58604,  Loss : 0.0,  Steps : 1000,  Global Steps : 206000 )\n",
      "207           15.287\n",
      "                   ( Result : 19.1714,  Loss : 0.0,  Steps : 1000,  Global Steps : 207000 )\n",
      "208           15.191\n",
      "                   ( Result : 7.26953,  Loss : 0.0,  Steps : 1000,  Global Steps : 208000 )\n",
      "209           15.093\n",
      "                   ( Result : 7.72031,  Loss : 0.0,  Steps : 1000,  Global Steps : 209000 )\n",
      "210           14.976\n",
      "                   ( Result : 7.76547,  Loss : 0.0,  Steps : 1000,  Global Steps : 210000 )\n",
      "211           15.056\n",
      "                   ( Result : 20.04355,  Loss : 0.0,  Steps : 1000,  Global Steps : 211000 )\n",
      "212           15.215\n",
      "                   ( Result : 21.27384,  Loss : 0.0,  Steps : 1000,  Global Steps : 212000 )\n",
      "213           15.134\n",
      "                   ( Result : 11.40165,  Loss : 0.0,  Steps : 1000,  Global Steps : 213000 )\n",
      "214           15.236\n",
      "                   ( Result : 16.05475,  Loss : 0.0,  Steps : 1000,  Global Steps : 214000 )\n",
      "215           15.097\n",
      "                   ( Result : 4.16391,  Loss : 0.0,  Steps : 1000,  Global Steps : 215000 )\n",
      "216           15.043\n",
      "                   ( Result : 21.83631,  Loss : 0.0,  Steps : 1000,  Global Steps : 216000 )\n",
      "217           14.978\n",
      "                   ( Result : 18.27728,  Loss : 0.0,  Steps : 1000,  Global Steps : 217000 )\n",
      "218           15.023\n",
      "                   ( Result : 17.00839,  Loss : 0.0,  Steps : 1000,  Global Steps : 218000 )\n",
      "219           15.064\n",
      "                   ( Result : 13.36179,  Loss : 0.0,  Steps : 1000,  Global Steps : 219000 )\n",
      "220           15.068\n",
      "                   ( Result : 22.91036,  Loss : 0.0,  Steps : 1000,  Global Steps : 220000 )\n",
      "221           15.187\n",
      "                   ( Result : 19.9099,  Loss : 0.0,  Steps : 1000,  Global Steps : 221000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222           15.068\n",
      "                   ( Result : 6.66038,  Loss : 0.0,  Steps : 1000,  Global Steps : 222000 )\n",
      "223           15.115\n",
      "                   ( Result : 21.88305,  Loss : 0.0,  Steps : 1000,  Global Steps : 223000 )\n",
      "224           14.935\n",
      "                   ( Result : -1.75991,  Loss : 0.0,  Steps : 1000,  Global Steps : 224000 )\n",
      "225           14.911\n",
      "                   ( Result : 9.71763,  Loss : 0.0,  Steps : 1000,  Global Steps : 225000 )\n",
      "226           15.109\n",
      "                   ( Result : 15.76999,  Loss : 0.0,  Steps : 1000,  Global Steps : 226000 )\n",
      "227           15.157\n",
      "                   ( Result : 24.89463,  Loss : 0.0,  Steps : 1000,  Global Steps : 227000 )\n",
      "228           15.09\n",
      "                   ( Result : 19.26683,  Loss : 0.0,  Steps : 1000,  Global Steps : 228000 )\n",
      "229           14.964\n",
      "                   ( Result : 11.34781,  Loss : 0.0,  Steps : 1000,  Global Steps : 229000 )\n",
      "230           15.005\n",
      "                   ( Result : 12.21892,  Loss : 0.0,  Steps : 1000,  Global Steps : 230000 )\n",
      "231           15.113\n",
      "                   ( Result : 18.73158,  Loss : 0.0,  Steps : 1000,  Global Steps : 231000 )\n",
      "232           15.167\n",
      "                   ( Result : 15.48428,  Loss : 0.0,  Steps : 1000,  Global Steps : 232000 )\n",
      "233           15.075\n",
      "                   ( Result : 6.89522,  Loss : 0.0,  Steps : 1000,  Global Steps : 233000 )\n",
      "234           15.098\n",
      "                   ( Result : 13.34044,  Loss : 0.0,  Steps : 1000,  Global Steps : 234000 )\n",
      "235           14.996\n",
      "                   ( Result : 5.38714,  Loss : 0.0,  Steps : 1000,  Global Steps : 235000 )\n",
      "236           14.855\n",
      "                   ( Result : 11.05504,  Loss : 0.0,  Steps : 1000,  Global Steps : 236000 )\n",
      "237           14.817\n",
      "                   ( Result : 1.23124,  Loss : 0.0,  Steps : 1000,  Global Steps : 237000 )\n",
      "238           14.92\n",
      "                   ( Result : 20.73524,  Loss : 0.0,  Steps : 1000,  Global Steps : 238000 )\n",
      "239           14.882\n",
      "                   ( Result : 11.71591,  Loss : 0.0,  Steps : 1000,  Global Steps : 239000 )\n",
      "240           14.879\n",
      "                   ( Result : 19.23212,  Loss : 0.0,  Steps : 1000,  Global Steps : 240000 )\n",
      "241           14.834\n",
      "                   ( Result : 18.15625,  Loss : 0.0,  Steps : 1000,  Global Steps : 241000 )\n",
      "242           14.808\n",
      "                   ( Result : 17.19213,  Loss : 0.0,  Steps : 1000,  Global Steps : 242000 )\n",
      "243           15.012\n",
      "                   ( Result : 20.23558,  Loss : 0.0,  Steps : 1000,  Global Steps : 243000 )\n",
      "244           15.095\n",
      "                   ( Result : 12.68054,  Loss : 0.0,  Steps : 1000,  Global Steps : 244000 )\n",
      "245           15.113\n",
      "                   ( Result : 16.44835,  Loss : 0.0,  Steps : 1000,  Global Steps : 245000 )\n",
      "246           15.092\n",
      "                   ( Result : 12.24954,  Loss : 0.0,  Steps : 1000,  Global Steps : 246000 )\n",
      "247           15.211\n",
      "                   ( Result : 17.32141,  Loss : 0.0,  Steps : 1000,  Global Steps : 247000 )\n",
      "248           15.248\n",
      "                   ( Result : 16.61854,  Loss : 0.0,  Steps : 1000,  Global Steps : 248000 )\n",
      "249           15.154\n",
      "                   ( Result : 11.225,  Loss : 0.0,  Steps : 1000,  Global Steps : 249000 )\n",
      "250           15.082\n",
      "                   ( Result : 8.61143,  Loss : 0.0,  Steps : 1000,  Global Steps : 250000 )\n",
      "251           14.94\n",
      "                   ( Result : 3.72797,  Loss : 0.0,  Steps : 1000,  Global Steps : 251000 )\n",
      "252           14.895\n",
      "                   ( Result : 10.33342,  Loss : 0.0,  Steps : 1000,  Global Steps : 252000 )\n",
      "253           14.872\n",
      "                   ( Result : 11.40412,  Loss : 0.0,  Steps : 1000,  Global Steps : 253000 )\n",
      "254           14.998\n",
      "                   ( Result : 15.33459,  Loss : 0.0,  Steps : 1000,  Global Steps : 254000 )\n",
      "255           14.904\n",
      "                   ( Result : 16.37354,  Loss : 0.0,  Steps : 1000,  Global Steps : 255000 )\n",
      "256           15.002\n",
      "                   ( Result : 21.9045,  Loss : 0.0,  Steps : 1000,  Global Steps : 256000 )\n",
      "257           14.902\n",
      "                   ( Result : 10.5514,  Loss : 0.0,  Steps : 1000,  Global Steps : 257000 )\n",
      "258           14.922\n",
      "                   ( Result : 27.92171,  Loss : 0.0,  Steps : 1000,  Global Steps : 258000 )\n",
      "259           14.771\n",
      "                   ( Result : 9.993,  Loss : 0.0,  Steps : 1000,  Global Steps : 259000 )\n",
      "260           14.668\n",
      "                   ( Result : 15.12431,  Loss : 0.0,  Steps : 1000,  Global Steps : 260000 )\n",
      "261           14.521\n",
      "                   ( Result : 3.9439,  Loss : 0.0,  Steps : 1000,  Global Steps : 261000 )\n",
      "262           14.51\n",
      "                   ( Result : 24.23896,  Loss : 0.0,  Steps : 1000,  Global Steps : 262000 )\n",
      "263           14.599\n",
      "                   ( Result : 25.99113,  Loss : 0.0,  Steps : 1000,  Global Steps : 263000 )\n",
      "264           14.63\n",
      "                   ( Result : 8.8596,  Loss : 0.0,  Steps : 1000,  Global Steps : 264000 )\n",
      "265           14.633\n",
      "                   ( Result : 13.82815,  Loss : 0.0,  Steps : 1000,  Global Steps : 265000 )\n",
      "266           14.509\n",
      "                   ( Result : 9.27092,  Loss : 0.0,  Steps : 1000,  Global Steps : 266000 )\n",
      "267           14.477\n",
      "                   ( Result : -1.10041,  Loss : 0.0,  Steps : 1000,  Global Steps : 267000 )\n",
      "268           14.507\n",
      "                   ( Result : 16.62775,  Loss : 0.0,  Steps : 1000,  Global Steps : 268000 )\n",
      "269           14.628\n",
      "                   ( Result : 18.87837,  Loss : 0.0,  Steps : 1000,  Global Steps : 269000 )\n",
      "270           14.626\n",
      "                   ( Result : 24.91428,  Loss : 0.0,  Steps : 1000,  Global Steps : 270000 )\n",
      "271           14.758\n",
      "                   ( Result : 18.45691,  Loss : 0.0,  Steps : 1000,  Global Steps : 271000 )\n",
      "272           14.852\n",
      "                   ( Result : 24.16163,  Loss : 0.0,  Steps : 1000,  Global Steps : 272000 )\n",
      "273           14.718\n",
      "                   ( Result : 7.91003,  Loss : 0.0,  Steps : 1000,  Global Steps : 273000 )\n",
      "274           14.746\n",
      "                   ( Result : 12.5233,  Loss : 0.0,  Steps : 1000,  Global Steps : 274000 )\n",
      "275           14.745\n",
      "                   ( Result : 11.83031,  Loss : 0.0,  Steps : 1000,  Global Steps : 275000 )\n",
      "276           14.854\n",
      "                   ( Result : 19.34144,  Loss : 0.0,  Steps : 1000,  Global Steps : 276000 )\n",
      "277           14.804\n",
      "                   ( Result : 13.06306,  Loss : 0.0,  Steps : 1000,  Global Steps : 277000 )\n",
      "278           14.971\n",
      "                   ( Result : 14.14894,  Loss : 0.0,  Steps : 1000,  Global Steps : 278000 )\n",
      "279           15.05\n",
      "                   ( Result : 27.85949,  Loss : 0.0,  Steps : 1000,  Global Steps : 279000 )\n",
      "280           14.83\n",
      "                   ( Result : 2.75991,  Loss : 0.0,  Steps : 1000,  Global Steps : 280000 )\n",
      "281           14.596\n",
      "                   ( Result : 1.04799,  Loss : 0.0,  Steps : 1000,  Global Steps : 281000 )\n",
      "282           14.473\n",
      "                   ( Result : 2.92726,  Loss : 0.0,  Steps : 1000,  Global Steps : 282000 )\n",
      "283           14.615\n",
      "                   ( Result : 18.00226,  Loss : 0.0,  Steps : 1000,  Global Steps : 283000 )\n",
      "284           14.471\n",
      "                   ( Result : -0.89908,  Loss : 0.0,  Steps : 1000,  Global Steps : 284000 )\n",
      "285           14.455\n",
      "                   ( Result : 14.48638,  Loss : 0.0,  Steps : 1000,  Global Steps : 285000 )\n",
      "286           14.382\n",
      "                   ( Result : 12.45264,  Loss : 0.0,  Steps : 1000,  Global Steps : 286000 )\n",
      "287           14.401\n",
      "                   ( Result : 13.12846,  Loss : 0.0,  Steps : 1000,  Global Steps : 287000 )\n",
      "288           14.476\n",
      "                   ( Result : 20.1893,  Loss : 0.0,  Steps : 1000,  Global Steps : 288000 )\n",
      "289           14.394\n",
      "                   ( Result : 15.02161,  Loss : 0.0,  Steps : 1000,  Global Steps : 289000 )\n",
      "290           14.428\n",
      "                   ( Result : 18.42369,  Loss : 0.0,  Steps : 1000,  Global Steps : 290000 )\n",
      "291           14.503\n",
      "                   ( Result : 25.62823,  Loss : 0.0,  Steps : 1000,  Global Steps : 291000 )\n",
      "292           14.452\n",
      "                   ( Result : 9.92693,  Loss : 0.0,  Steps : 1000,  Global Steps : 292000 )\n",
      "293           14.565\n",
      "                   ( Result : 20.31271,  Loss : 0.0,  Steps : 1000,  Global Steps : 293000 )\n",
      "294           14.642\n",
      "                   ( Result : 20.98448,  Loss : 0.0,  Steps : 1000,  Global Steps : 294000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295           14.424\n",
      "                   ( Result : 9.4179,  Loss : 0.0,  Steps : 1000,  Global Steps : 295000 )\n",
      "296           14.348\n",
      "                   ( Result : 9.56024,  Loss : 0.0,  Steps : 1000,  Global Steps : 296000 )\n",
      "297           14.435\n",
      "                   ( Result : 16.02288,  Loss : 0.0,  Steps : 1000,  Global Steps : 297000 )\n",
      "298           14.207\n",
      "                   ( Result : -2.3851,  Loss : 0.0,  Steps : 1000,  Global Steps : 298000 )\n",
      "299           14.015\n",
      "                   ( Result : 9.93038,  Loss : 0.0,  Steps : 1000,  Global Steps : 299000 )\n",
      "300           13.88\n",
      "                   ( Result : 4.50623,  Loss : 0.0,  Steps : 1000,  Global Steps : 300000 )\n",
      "301           13.856\n",
      "                   ( Result : 6.349,  Loss : 0.0,  Steps : 1000,  Global Steps : 301000 )\n",
      "302           13.882\n",
      "                   ( Result : 19.81579,  Loss : 0.0,  Steps : 1000,  Global Steps : 302000 )\n",
      "303           14.085\n",
      "                   ( Result : 22.3321,  Loss : 0.0,  Steps : 1000,  Global Steps : 303000 )\n",
      "304           13.852\n",
      "                   ( Result : -0.52144,  Loss : 0.0,  Steps : 1000,  Global Steps : 304000 )\n",
      "305           13.997\n",
      "                   ( Result : 25.61073,  Loss : 0.0,  Steps : 1000,  Global Steps : 305000 )\n",
      "306           13.97\n",
      "                   ( Result : 21.88544,  Loss : 0.0,  Steps : 1000,  Global Steps : 306000 )\n",
      "307           13.869\n",
      "                   ( Result : 9.02806,  Loss : 0.0,  Steps : 1000,  Global Steps : 307000 )\n",
      "308           13.951\n",
      "                   ( Result : 15.48272,  Loss : 0.0,  Steps : 1000,  Global Steps : 308000 )\n",
      "309           14.06\n",
      "                   ( Result : 18.57748,  Loss : 0.0,  Steps : 1000,  Global Steps : 309000 )\n",
      "310           14.224\n",
      "                   ( Result : 24.1779,  Loss : 0.0,  Steps : 1000,  Global Steps : 310000 )\n",
      "311           14.229\n",
      "                   ( Result : 20.51416,  Loss : 0.0,  Steps : 1000,  Global Steps : 311000 )\n",
      "312           14.335\n",
      "                   ( Result : 31.91607,  Loss : 0.0,  Steps : 1000,  Global Steps : 312000 )\n",
      "313           14.278\n",
      "                   ( Result : 5.66273,  Loss : 0.0,  Steps : 1000,  Global Steps : 313000 )\n",
      "314           14.364\n",
      "                   ( Result : 24.69786,  Loss : 0.0,  Steps : 1000,  Global Steps : 314000 )\n",
      "315           14.469\n",
      "                   ( Result : 14.69356,  Loss : 0.0,  Steps : 1000,  Global Steps : 315000 )\n",
      "316           14.324\n",
      "                   ( Result : 7.28859,  Loss : 0.0,  Steps : 1000,  Global Steps : 316000 )\n",
      "317           14.185\n",
      "                   ( Result : 4.3987,  Loss : 0.0,  Steps : 1000,  Global Steps : 317000 )\n",
      "318           14.205\n",
      "                   ( Result : 18.9623,  Loss : 0.0,  Steps : 1000,  Global Steps : 318000 )\n",
      "319           14.176\n",
      "                   ( Result : 10.46317,  Loss : 0.0,  Steps : 1000,  Global Steps : 319000 )\n",
      "320           14.039\n",
      "                   ( Result : 9.24403,  Loss : 0.0,  Steps : 1000,  Global Steps : 320000 )\n",
      "321           13.948\n",
      "                   ( Result : 10.86233,  Loss : 0.0,  Steps : 1000,  Global Steps : 321000 )\n",
      "322           14.05\n",
      "                   ( Result : 16.84901,  Loss : 0.0,  Steps : 1000,  Global Steps : 322000 )\n",
      "323           14.004\n",
      "                   ( Result : 17.26663,  Loss : 0.0,  Steps : 1000,  Global Steps : 323000 )\n",
      "324           14.251\n",
      "                   ( Result : 22.92159,  Loss : 0.0,  Steps : 1000,  Global Steps : 324000 )\n",
      "325           14.306\n",
      "                   ( Result : 15.22751,  Loss : 0.0,  Steps : 1000,  Global Steps : 325000 )\n",
      "326           14.359\n",
      "                   ( Result : 21.09749,  Loss : 0.0,  Steps : 1000,  Global Steps : 326000 )\n",
      "327           14.218\n",
      "                   ( Result : 10.80255,  Loss : 0.0,  Steps : 1000,  Global Steps : 327000 )\n",
      "328           14.161\n",
      "                   ( Result : 13.56166,  Loss : 0.0,  Steps : 1000,  Global Steps : 328000 )\n",
      "329           14.033\n",
      "                   ( Result : -1.45663,  Loss : 0.0,  Steps : 1000,  Global Steps : 329000 )\n",
      "330           14.01\n",
      "                   ( Result : 9.8591,  Loss : 0.0,  Steps : 1000,  Global Steps : 330000 )\n",
      "331           14.04\n",
      "                   ( Result : 21.72919,  Loss : 0.0,  Steps : 1000,  Global Steps : 331000 )\n",
      "332           14.079\n",
      "                   ( Result : 19.44709,  Loss : 0.0,  Steps : 1000,  Global Steps : 332000 )\n",
      "333           14.258\n",
      "                   ( Result : 24.80216,  Loss : 0.0,  Steps : 1000,  Global Steps : 333000 )\n",
      "334           14.279\n",
      "                   ( Result : 15.44326,  Loss : 0.0,  Steps : 1000,  Global Steps : 334000 )\n",
      "335           14.304\n",
      "                   ( Result : 7.86906,  Loss : 0.0,  Steps : 1000,  Global Steps : 335000 )\n",
      "336           14.263\n",
      "                   ( Result : 6.93921,  Loss : 0.0,  Steps : 1000,  Global Steps : 336000 )\n",
      "337           14.27\n",
      "                   ( Result : 1.89757,  Loss : 0.0,  Steps : 1000,  Global Steps : 337000 )\n",
      "338           14.251\n",
      "                   ( Result : 18.80723,  Loss : 0.0,  Steps : 1000,  Global Steps : 338000 )\n",
      "339           14.423\n",
      "                   ( Result : 28.98198,  Loss : 0.0,  Steps : 1000,  Global Steps : 339000 )\n",
      "340           14.262\n",
      "                   ( Result : 3.11422,  Loss : 0.0,  Steps : 1000,  Global Steps : 340000 )\n",
      "341           14.164\n",
      "                   ( Result : 8.34619,  Loss : 0.0,  Steps : 1000,  Global Steps : 341000 )\n",
      "342           14.135\n",
      "                   ( Result : 14.34777,  Loss : 0.0,  Steps : 1000,  Global Steps : 342000 )\n",
      "343           14.029\n",
      "                   ( Result : 9.57757,  Loss : 0.0,  Steps : 1000,  Global Steps : 343000 )\n",
      "344           14.09\n",
      "                   ( Result : 18.84114,  Loss : 0.0,  Steps : 1000,  Global Steps : 344000 )\n",
      "345           14.102\n",
      "                   ( Result : 17.64136,  Loss : 0.0,  Steps : 1000,  Global Steps : 345000 )\n",
      "346           14.073\n",
      "                   ( Result : 9.31554,  Loss : 0.0,  Steps : 1000,  Global Steps : 346000 )\n",
      "347           14.146\n",
      "                   ( Result : 24.5893,  Loss : 0.0,  Steps : 1000,  Global Steps : 347000 )\n",
      "348           14.104\n",
      "                   ( Result : 12.42667,  Loss : 0.0,  Steps : 1000,  Global Steps : 348000 )\n",
      "349           14.296\n",
      "                   ( Result : 30.43425,  Loss : 0.0,  Steps : 1000,  Global Steps : 349000 )\n",
      "350           14.443\n",
      "                   ( Result : 23.33847,  Loss : 0.0,  Steps : 1000,  Global Steps : 350000 )\n",
      "351           14.545\n",
      "                   ( Result : 13.94828,  Loss : 0.0,  Steps : 1000,  Global Steps : 351000 )\n",
      "352           14.729\n",
      "                   ( Result : 28.68445,  Loss : 0.0,  Steps : 1000,  Global Steps : 352000 )\n",
      "353           14.901\n",
      "                   ( Result : 28.62455,  Loss : 0.0,  Steps : 1000,  Global Steps : 353000 )\n",
      "354           14.899\n",
      "                   ( Result : 15.17,  Loss : 0.0,  Steps : 1000,  Global Steps : 354000 )\n",
      "355           14.883\n",
      "                   ( Result : 14.68034,  Loss : 0.0,  Steps : 1000,  Global Steps : 355000 )\n",
      "356           14.919\n",
      "                   ( Result : 25.55393,  Loss : 0.0,  Steps : 1000,  Global Steps : 356000 )\n",
      "357           14.762\n",
      "                   ( Result : -5.11728,  Loss : 0.0,  Steps : 1000,  Global Steps : 357000 )\n",
      "358           14.596\n",
      "                   ( Result : 11.24444,  Loss : 0.0,  Steps : 1000,  Global Steps : 358000 )\n",
      "359           14.672\n",
      "                   ( Result : 17.60645,  Loss : 0.0,  Steps : 1000,  Global Steps : 359000 )\n",
      "360           14.541\n",
      "                   ( Result : 2.07938,  Loss : 0.0,  Steps : 1000,  Global Steps : 360000 )\n",
      "361           14.568\n",
      "                   ( Result : 6.63916,  Loss : 0.0,  Steps : 1000,  Global Steps : 361000 )\n",
      "362           14.573\n",
      "                   ( Result : 24.68553,  Loss : 0.0,  Steps : 1000,  Global Steps : 362000 )\n",
      "363           14.485\n",
      "                   ( Result : 17.21103,  Loss : 0.0,  Steps : 1000,  Global Steps : 363000 )\n",
      "364           14.498\n",
      "                   ( Result : 10.14234,  Loss : 0.0,  Steps : 1000,  Global Steps : 364000 )\n",
      "365           14.49\n",
      "                   ( Result : 13.10659,  Loss : 0.0,  Steps : 1000,  Global Steps : 365000 )\n",
      "366           14.627\n",
      "                   ( Result : 22.94483,  Loss : 0.0,  Steps : 1000,  Global Steps : 366000 )\n",
      "367           14.687\n",
      "                   ( Result : 4.881,  Loss : 0.0,  Steps : 1000,  Global Steps : 367000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368           14.635\n",
      "                   ( Result : 11.41305,  Loss : 0.0,  Steps : 1000,  Global Steps : 368000 )\n",
      "369           14.728\n",
      "                   ( Result : 28.17846,  Loss : 0.0,  Steps : 1000,  Global Steps : 369000 )\n",
      "370           14.636\n",
      "                   ( Result : 15.757,  Loss : 0.0,  Steps : 1000,  Global Steps : 370000 )\n",
      "371           14.656\n",
      "                   ( Result : 20.41466,  Loss : 0.0,  Steps : 1000,  Global Steps : 371000 )\n",
      "372           14.544\n",
      "                   ( Result : 12.93929,  Loss : 0.0,  Steps : 1000,  Global Steps : 372000 )\n",
      "373           14.533\n",
      "                   ( Result : 6.83315,  Loss : 0.0,  Steps : 1000,  Global Steps : 373000 )\n",
      "374           14.404\n",
      "                   ( Result : -0.3976,  Loss : 0.0,  Steps : 1000,  Global Steps : 374000 )\n",
      "375           14.497\n",
      "                   ( Result : 21.14424,  Loss : 0.0,  Steps : 1000,  Global Steps : 375000 )\n",
      "376           14.528\n",
      "                   ( Result : 22.46201,  Loss : 0.0,  Steps : 1000,  Global Steps : 376000 )\n",
      "377           14.414\n",
      "                   ( Result : 1.65775,  Loss : 0.0,  Steps : 1000,  Global Steps : 377000 )\n",
      "378           14.273\n",
      "                   ( Result : 0.06131,  Loss : 0.0,  Steps : 1000,  Global Steps : 378000 )\n",
      "379           14.121\n",
      "                   ( Result : 12.64929,  Loss : 0.0,  Steps : 1000,  Global Steps : 379000 )\n",
      "380           14.263\n",
      "                   ( Result : 16.92373,  Loss : 0.0,  Steps : 1000,  Global Steps : 380000 )\n",
      "381           14.429\n",
      "                   ( Result : 17.67917,  Loss : 0.0,  Steps : 1000,  Global Steps : 381000 )\n",
      "382           14.384\n",
      "                   ( Result : -1.54051,  Loss : 0.0,  Steps : 1000,  Global Steps : 382000 )\n",
      "383           14.268\n",
      "                   ( Result : 6.36608,  Loss : 0.0,  Steps : 1000,  Global Steps : 383000 )\n",
      "384           14.349\n",
      "                   ( Result : 7.25704,  Loss : 0.0,  Steps : 1000,  Global Steps : 384000 )\n",
      "385           14.391\n",
      "                   ( Result : 18.64183,  Loss : 0.0,  Steps : 1000,  Global Steps : 385000 )\n",
      "386           14.417\n",
      "                   ( Result : 15.07466,  Loss : 0.0,  Steps : 1000,  Global Steps : 386000 )\n",
      "387           14.439\n",
      "                   ( Result : 15.31468,  Loss : 0.0,  Steps : 1000,  Global Steps : 387000 )\n",
      "388           14.399\n",
      "                   ( Result : 16.21208,  Loss : 0.0,  Steps : 1000,  Global Steps : 388000 )\n",
      "389           14.311\n",
      "                   ( Result : 6.22541,  Loss : 0.0,  Steps : 1000,  Global Steps : 389000 )\n",
      "390           14.325\n",
      "                   ( Result : 19.81227,  Loss : 0.0,  Steps : 1000,  Global Steps : 390000 )\n",
      "391           14.299\n",
      "                   ( Result : 22.9711,  Loss : 0.0,  Steps : 1000,  Global Steps : 391000 )\n",
      "392           14.161\n",
      "                   ( Result : -3.79478,  Loss : 0.0,  Steps : 1000,  Global Steps : 392000 )\n",
      "393           14.137\n",
      "                   ( Result : 17.88406,  Loss : 0.0,  Steps : 1000,  Global Steps : 393000 )\n",
      "394           14.081\n",
      "                   ( Result : 15.41029,  Loss : 0.0,  Steps : 1000,  Global Steps : 394000 )\n",
      "395           14.29\n",
      "                   ( Result : 30.23823,  Loss : 0.0,  Steps : 1000,  Global Steps : 395000 )\n",
      "396           14.374\n",
      "                   ( Result : 17.96524,  Loss : 0.0,  Steps : 1000,  Global Steps : 396000 )\n",
      "397           14.401\n",
      "                   ( Result : 18.78811,  Loss : 0.0,  Steps : 1000,  Global Steps : 397000 )\n",
      "398           14.643\n",
      "                   ( Result : 21.74703,  Loss : 0.0,  Steps : 1000,  Global Steps : 398000 )\n",
      "399           14.602\n",
      "                   ( Result : 5.90724,  Loss : 0.0,  Steps : 1000,  Global Steps : 399000 )\n",
      "400           14.649\n",
      "                   ( Result : 9.12864,  Loss : 0.0,  Steps : 1000,  Global Steps : 400000 )\n",
      "401           14.809\n",
      "                   ( Result : 22.3861,  Loss : 0.0,  Steps : 1000,  Global Steps : 401000 )\n",
      "402           14.725\n",
      "                   ( Result : 11.4407,  Loss : 0.0,  Steps : 1000,  Global Steps : 402000 )\n",
      "403           14.683\n",
      "                   ( Result : 18.08069,  Loss : 0.0,  Steps : 1000,  Global Steps : 403000 )\n",
      "404           14.882\n",
      "                   ( Result : 19.37152,  Loss : 0.0,  Steps : 1000,  Global Steps : 404000 )\n",
      "405           14.869\n",
      "                   ( Result : 24.32501,  Loss : 0.0,  Steps : 1000,  Global Steps : 405000 )\n",
      "406           14.827\n",
      "                   ( Result : 17.73743,  Loss : 0.0,  Steps : 1000,  Global Steps : 406000 )\n",
      "407           14.996\n",
      "                   ( Result : 25.93664,  Loss : 0.0,  Steps : 1000,  Global Steps : 407000 )\n",
      "408           15.071\n",
      "                   ( Result : 22.96021,  Loss : 0.0,  Steps : 1000,  Global Steps : 408000 )\n",
      "409           15.16\n",
      "                   ( Result : 27.42954,  Loss : 0.0,  Steps : 1000,  Global Steps : 409000 )\n",
      "410           15.084\n",
      "                   ( Result : 16.57354,  Loss : 0.0,  Steps : 1000,  Global Steps : 410000 )\n",
      "411           15.016\n",
      "                   ( Result : 13.76572,  Loss : 0.0,  Steps : 1000,  Global Steps : 411000 )\n",
      "412           14.936\n",
      "                   ( Result : 23.87557,  Loss : 0.0,  Steps : 1000,  Global Steps : 412000 )\n",
      "413           14.931\n",
      "                   ( Result : 5.17878,  Loss : 0.0,  Steps : 1000,  Global Steps : 413000 )\n",
      "414           14.916\n",
      "                   ( Result : 23.15339,  Loss : 0.0,  Steps : 1000,  Global Steps : 414000 )\n",
      "415           14.956\n",
      "                   ( Result : 18.77349,  Loss : 0.0,  Steps : 1000,  Global Steps : 415000 )\n",
      "416           15.013\n",
      "                   ( Result : 12.92905,  Loss : 0.0,  Steps : 1000,  Global Steps : 416000 )\n",
      "417           15.204\n",
      "                   ( Result : 23.51916,  Loss : 0.0,  Steps : 1000,  Global Steps : 417000 )\n",
      "418           15.045\n",
      "                   ( Result : 3.05008,  Loss : 0.0,  Steps : 1000,  Global Steps : 418000 )\n",
      "419           14.999\n",
      "                   ( Result : 5.85645,  Loss : 0.0,  Steps : 1000,  Global Steps : 419000 )\n",
      "420           15.087\n",
      "                   ( Result : 18.02319,  Loss : 0.0,  Steps : 1000,  Global Steps : 420000 )\n",
      "421           14.947\n",
      "                   ( Result : -3.10738,  Loss : 0.0,  Steps : 1000,  Global Steps : 421000 )\n",
      "422           14.916\n",
      "                   ( Result : 13.79059,  Loss : 0.0,  Steps : 1000,  Global Steps : 422000 )\n",
      "423           14.784\n",
      "                   ( Result : 4.00896,  Loss : 0.0,  Steps : 1000,  Global Steps : 423000 )\n",
      "424           14.725\n",
      "                   ( Result : 17.02961,  Loss : 0.0,  Steps : 1000,  Global Steps : 424000 )\n",
      "425           14.539\n",
      "                   ( Result : -3.32672,  Loss : 0.0,  Steps : 1000,  Global Steps : 425000 )\n",
      "426           14.348\n",
      "                   ( Result : 2.01944,  Loss : 0.0,  Steps : 1000,  Global Steps : 426000 )\n",
      "427           14.269\n",
      "                   ( Result : 2.87278,  Loss : 0.0,  Steps : 1000,  Global Steps : 427000 )\n",
      "428           14.316\n",
      "                   ( Result : 18.27228,  Loss : 0.0,  Steps : 1000,  Global Steps : 428000 )\n",
      "429           14.469\n",
      "                   ( Result : 13.82164,  Loss : 0.0,  Steps : 1000,  Global Steps : 429000 )\n",
      "430           14.541\n",
      "                   ( Result : 17.0071,  Loss : 0.0,  Steps : 1000,  Global Steps : 430000 )\n",
      "431           14.581\n",
      "                   ( Result : 25.79979,  Loss : 0.0,  Steps : 1000,  Global Steps : 431000 )\n",
      "432           14.634\n",
      "                   ( Result : 24.74003,  Loss : 0.0,  Steps : 1000,  Global Steps : 432000 )\n",
      "433           14.563\n",
      "                   ( Result : 17.68127,  Loss : 0.0,  Steps : 1000,  Global Steps : 433000 )\n",
      "434           14.535\n",
      "                   ( Result : 12.63173,  Loss : 0.0,  Steps : 1000,  Global Steps : 434000 )\n",
      "435           14.565\n",
      "                   ( Result : 10.8404,  Loss : 0.0,  Steps : 1000,  Global Steps : 435000 )\n",
      "436           14.54\n",
      "                   ( Result : 4.5297,  Loss : 0.0,  Steps : 1000,  Global Steps : 436000 )\n",
      "437           14.731\n",
      "                   ( Result : 20.99136,  Loss : 0.0,  Steps : 1000,  Global Steps : 437000 )\n",
      "438           14.744\n",
      "                   ( Result : 20.02384,  Loss : 0.0,  Steps : 1000,  Global Steps : 438000 )\n",
      "439           14.684\n",
      "                   ( Result : 23.02923,  Loss : 0.0,  Steps : 1000,  Global Steps : 439000 )\n",
      "440           14.866\n",
      "                   ( Result : 21.28503,  Loss : 0.0,  Steps : 1000,  Global Steps : 440000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441           15.018\n",
      "                   ( Result : 23.57124,  Loss : 0.0,  Steps : 1000,  Global Steps : 441000 )\n",
      "442           15.119\n",
      "                   ( Result : 24.4475,  Loss : 0.0,  Steps : 1000,  Global Steps : 442000 )\n",
      "443           15.113\n",
      "                   ( Result : 8.93811,  Loss : 0.0,  Steps : 1000,  Global Steps : 443000 )\n",
      "444           15.097\n",
      "                   ( Result : 17.24211,  Loss : 0.0,  Steps : 1000,  Global Steps : 444000 )\n",
      "445           15.052\n",
      "                   ( Result : 13.22277,  Loss : 0.0,  Steps : 1000,  Global Steps : 445000 )\n",
      "446           15.099\n",
      "                   ( Result : 13.96686,  Loss : 0.0,  Steps : 1000,  Global Steps : 446000 )\n",
      "447           15.081\n",
      "                   ( Result : 22.83101,  Loss : 0.0,  Steps : 1000,  Global Steps : 447000 )\n",
      "448           15.091\n",
      "                   ( Result : 13.38538,  Loss : 0.0,  Steps : 1000,  Global Steps : 448000 )\n",
      "449           14.796\n",
      "                   ( Result : 0.95213,  Loss : 0.0,  Steps : 1000,  Global Steps : 449000 )\n",
      "450           14.697\n",
      "                   ( Result : 13.39778,  Loss : 0.0,  Steps : 1000,  Global Steps : 450000 )\n",
      "451           14.542\n",
      "                   ( Result : -1.5115,  Loss : 0.0,  Steps : 1000,  Global Steps : 451000 )\n",
      "452           14.443\n",
      "                   ( Result : 18.76898,  Loss : 0.0,  Steps : 1000,  Global Steps : 452000 )\n",
      "453           14.342\n",
      "                   ( Result : 18.56243,  Loss : 0.0,  Steps : 1000,  Global Steps : 453000 )\n",
      "454           14.392\n",
      "                   ( Result : 20.17324,  Loss : 0.0,  Steps : 1000,  Global Steps : 454000 )\n",
      "455           14.479\n",
      "                   ( Result : 23.33486,  Loss : 0.0,  Steps : 1000,  Global Steps : 455000 )\n",
      "456           14.471\n",
      "                   ( Result : 24.72618,  Loss : 0.0,  Steps : 1000,  Global Steps : 456000 )\n",
      "457           14.656\n",
      "                   ( Result : 13.40938,  Loss : 0.0,  Steps : 1000,  Global Steps : 457000 )\n",
      "458           14.505\n",
      "                   ( Result : -3.88005,  Loss : 0.0,  Steps : 1000,  Global Steps : 458000 )\n",
      "459           14.404\n",
      "                   ( Result : 7.5357,  Loss : 0.0,  Steps : 1000,  Global Steps : 459000 )\n",
      "460           14.508\n",
      "                   ( Result : 12.50173,  Loss : 0.0,  Steps : 1000,  Global Steps : 460000 )\n",
      "461           14.554\n",
      "                   ( Result : 11.2473,  Loss : 0.0,  Steps : 1000,  Global Steps : 461000 )\n",
      "462           14.549\n",
      "                   ( Result : 24.15512,  Loss : 0.0,  Steps : 1000,  Global Steps : 462000 )\n",
      "463           14.665\n",
      "                   ( Result : 28.79672,  Loss : 0.0,  Steps : 1000,  Global Steps : 463000 )\n",
      "464           14.766\n",
      "                   ( Result : 20.25598,  Loss : 0.0,  Steps : 1000,  Global Steps : 464000 )\n",
      "465           14.7\n",
      "                   ( Result : 6.52259,  Loss : 0.0,  Steps : 1000,  Global Steps : 465000 )\n",
      "466           14.671\n",
      "                   ( Result : 20.01907,  Loss : 0.0,  Steps : 1000,  Global Steps : 466000 )\n",
      "467           14.653\n",
      "                   ( Result : 3.1263,  Loss : 0.0,  Steps : 1000,  Global Steps : 467000 )\n",
      "468           14.744\n",
      "                   ( Result : 20.46609,  Loss : 0.0,  Steps : 1000,  Global Steps : 468000 )\n",
      "469           14.585\n",
      "                   ( Result : 12.29981,  Loss : 0.0,  Steps : 1000,  Global Steps : 469000 )\n",
      "470           14.556\n",
      "                   ( Result : 12.87802,  Loss : 0.0,  Steps : 1000,  Global Steps : 470000 )\n",
      "471           14.473\n",
      "                   ( Result : 12.06404,  Loss : 0.0,  Steps : 1000,  Global Steps : 471000 )\n",
      "472           14.536\n",
      "                   ( Result : 19.25682,  Loss : 0.0,  Steps : 1000,  Global Steps : 472000 )\n",
      "473           14.659\n",
      "                   ( Result : 19.09353,  Loss : 0.0,  Steps : 1000,  Global Steps : 473000 )\n",
      "474           14.776\n",
      "                   ( Result : 11.37983,  Loss : 0.0,  Steps : 1000,  Global Steps : 474000 )\n",
      "475           14.698\n",
      "                   ( Result : 13.32888,  Loss : 0.0,  Steps : 1000,  Global Steps : 475000 )\n",
      "476           14.644\n",
      "                   ( Result : 17.00152,  Loss : 0.0,  Steps : 1000,  Global Steps : 476000 )\n",
      "477           14.805\n",
      "                   ( Result : 17.84275,  Loss : 0.0,  Steps : 1000,  Global Steps : 477000 )\n",
      "478           14.779\n",
      "                   ( Result : -2.61964,  Loss : 0.0,  Steps : 1000,  Global Steps : 478000 )\n",
      "479           14.914\n",
      "                   ( Result : 26.20968,  Loss : 0.0,  Steps : 1000,  Global Steps : 479000 )\n",
      "480           14.917\n",
      "                   ( Result : 17.17698,  Loss : 0.0,  Steps : 1000,  Global Steps : 480000 )\n",
      "481           14.833\n",
      "                   ( Result : 9.26602,  Loss : 0.0,  Steps : 1000,  Global Steps : 481000 )\n",
      "482           15.01\n",
      "                   ( Result : 16.22351,  Loss : 0.0,  Steps : 1000,  Global Steps : 482000 )\n",
      "483           15.177\n",
      "                   ( Result : 23.05803,  Loss : 0.0,  Steps : 1000,  Global Steps : 483000 )\n",
      "484           15.122\n",
      "                   ( Result : 1.72009,  Loss : 0.0,  Steps : 1000,  Global Steps : 484000 )\n",
      "485           14.984\n",
      "                   ( Result : 4.91251,  Loss : 0.0,  Steps : 1000,  Global Steps : 485000 )\n",
      "486           14.984\n",
      "                   ( Result : 15.06494,  Loss : 0.0,  Steps : 1000,  Global Steps : 486000 )\n",
      "487           15.038\n",
      "                   ( Result : 20.70505,  Loss : 0.0,  Steps : 1000,  Global Steps : 487000 )\n",
      "488           14.962\n",
      "                   ( Result : 8.6058,  Loss : 0.0,  Steps : 1000,  Global Steps : 488000 )\n",
      "489           15.004\n",
      "                   ( Result : 10.43806,  Loss : 0.0,  Steps : 1000,  Global Steps : 489000 )\n",
      "490           15.04\n",
      "                   ( Result : 23.33613,  Loss : 0.0,  Steps : 1000,  Global Steps : 490000 )\n",
      "491           14.873\n",
      "                   ( Result : 6.33596,  Loss : 0.0,  Steps : 1000,  Global Steps : 491000 )\n",
      "492           15.002\n",
      "                   ( Result : 9.03898,  Loss : 0.0,  Steps : 1000,  Global Steps : 492000 )\n",
      "493           15.037\n",
      "                   ( Result : 21.47099,  Loss : 0.0,  Steps : 1000,  Global Steps : 493000 )\n",
      "494           15.027\n",
      "                   ( Result : 14.36539,  Loss : 0.0,  Steps : 1000,  Global Steps : 494000 )\n",
      "495           15.012\n",
      "                   ( Result : 28.75407,  Loss : 0.0,  Steps : 1000,  Global Steps : 495000 )\n",
      "496           15.113\n",
      "                   ( Result : 28.09055,  Loss : 0.0,  Steps : 1000,  Global Steps : 496000 )\n",
      "497           15.179\n",
      "                   ( Result : 25.32425,  Loss : 0.0,  Steps : 1000,  Global Steps : 497000 )\n",
      "498           15.106\n",
      "                   ( Result : 14.44246,  Loss : 0.0,  Steps : 1000,  Global Steps : 498000 )\n",
      "499           15.282\n",
      "                   ( Result : 23.55489,  Loss : 0.0,  Steps : 1000,  Global Steps : 499000 )\n",
      "500           15.225\n",
      "                   ( Result : 3.39572,  Loss : 0.0,  Steps : 1000,  Global Steps : 500000 )\n",
      "501           15.25\n",
      "                   ( Result : 24.86652,  Loss : 0.0,  Steps : 1000,  Global Steps : 501000 )\n",
      "502           15.286\n",
      "                   ( Result : 15.04864,  Loss : 0.0,  Steps : 1000,  Global Steps : 502000 )\n",
      "503           15.135\n",
      "                   ( Result : 3.02523,  Loss : 0.0,  Steps : 1000,  Global Steps : 503000 )\n",
      "504           15.015\n",
      "                   ( Result : 7.35653,  Loss : 0.0,  Steps : 1000,  Global Steps : 504000 )\n",
      "505           15.08\n",
      "                   ( Result : 30.77421,  Loss : 0.0,  Steps : 1000,  Global Steps : 505000 )\n",
      "506           15.113\n",
      "                   ( Result : 21.10458,  Loss : 0.0,  Steps : 1000,  Global Steps : 506000 )\n",
      "507           15.013\n",
      "                   ( Result : 15.93202,  Loss : 0.0,  Steps : 1000,  Global Steps : 507000 )\n",
      "508           14.891\n",
      "                   ( Result : 10.71425,  Loss : 0.0,  Steps : 1000,  Global Steps : 508000 )\n",
      "509           14.727\n",
      "                   ( Result : 11.10109,  Loss : 0.0,  Steps : 1000,  Global Steps : 509000 )\n",
      "510           14.794\n",
      "                   ( Result : 23.22746,  Loss : 0.0,  Steps : 1000,  Global Steps : 510000 )\n",
      "511           14.865\n",
      "                   ( Result : 20.90573,  Loss : 0.0,  Steps : 1000,  Global Steps : 511000 )\n",
      "512           14.641\n",
      "                   ( Result : 1.38941,  Loss : 0.0,  Steps : 1000,  Global Steps : 512000 )\n",
      "513           14.757\n",
      "                   ( Result : 16.80609,  Loss : 0.0,  Steps : 1000,  Global Steps : 513000 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514           14.498\n",
      "                   ( Result : -2.76202,  Loss : 0.0,  Steps : 1000,  Global Steps : 514000 )\n",
      "515           14.498\n",
      "                   ( Result : 18.81918,  Loss : 0.0,  Steps : 1000,  Global Steps : 515000 )\n",
      "516           14.556\n",
      "                   ( Result : 18.67511,  Loss : 0.0,  Steps : 1000,  Global Steps : 516000 )\n",
      "517           14.482\n",
      "                   ( Result : 16.15684,  Loss : 0.0,  Steps : 1000,  Global Steps : 517000 )\n",
      "518           14.468\n",
      "                   ( Result : 1.60881,  Loss : 0.0,  Steps : 1000,  Global Steps : 518000 )\n",
      "519           14.606\n",
      "                   ( Result : 19.71261,  Loss : 0.0,  Steps : 1000,  Global Steps : 519000 )\n",
      "520           14.567\n",
      "                   ( Result : 14.16166,  Loss : 0.0,  Steps : 1000,  Global Steps : 520000 )\n",
      "521           14.861\n",
      "                   ( Result : 26.26913,  Loss : 0.0,  Steps : 1000,  Global Steps : 521000 )\n",
      "522           14.837\n",
      "                   ( Result : 11.38792,  Loss : 0.0,  Steps : 1000,  Global Steps : 522000 )\n",
      "523           15.029\n",
      "                   ( Result : 23.18802,  Loss : 0.0,  Steps : 1000,  Global Steps : 523000 )\n",
      "524           15.037\n",
      "                   ( Result : 17.85871,  Loss : 0.0,  Steps : 1000,  Global Steps : 524000 )\n",
      "525           15.221\n",
      "                   ( Result : 15.06879,  Loss : 0.0,  Steps : 1000,  Global Steps : 525000 )\n",
      "526           15.433\n",
      "                   ( Result : 23.16826,  Loss : 0.0,  Steps : 1000,  Global Steps : 526000 )\n",
      "527           15.493\n",
      "                   ( Result : 8.87556,  Loss : 0.0,  Steps : 1000,  Global Steps : 527000 )\n",
      "528           15.365\n",
      "                   ( Result : 5.53734,  Loss : 0.0,  Steps : 1000,  Global Steps : 528000 )\n",
      "529           15.348\n",
      "                   ( Result : 12.05124,  Loss : 0.0,  Steps : 1000,  Global Steps : 529000 )\n",
      "530           15.162\n",
      "                   ( Result : -1.54557,  Loss : 0.0,  Steps : 1000,  Global Steps : 530000 )\n",
      "531           14.974\n",
      "                   ( Result : 6.9357,  Loss : 0.0,  Steps : 1000,  Global Steps : 531000 )\n",
      "532           14.903\n",
      "                   ( Result : 17.69607,  Loss : 0.0,  Steps : 1000,  Global Steps : 532000 )\n",
      "533           14.93\n",
      "                   ( Result : 20.35099,  Loss : 0.0,  Steps : 1000,  Global Steps : 533000 )\n",
      "534           15.084\n",
      "                   ( Result : 28.08003,  Loss : 0.0,  Steps : 1000,  Global Steps : 534000 )\n",
      "535           15.077\n",
      "                   ( Result : 10.07101,  Loss : 0.0,  Steps : 1000,  Global Steps : 535000 )\n",
      "536           15.034\n",
      "                   ( Result : 0.2867,  Loss : 0.0,  Steps : 1000,  Global Steps : 536000 )\n",
      "537           14.945\n",
      "                   ( Result : 12.09937,  Loss : 0.0,  Steps : 1000,  Global Steps : 537000 )\n",
      "538           14.871\n",
      "                   ( Result : 12.638,  Loss : 0.0,  Steps : 1000,  Global Steps : 538000 )\n",
      "539           14.69\n",
      "                   ( Result : 4.91534,  Loss : 0.0,  Steps : 1000,  Global Steps : 539000 )\n",
      "540           14.727\n",
      "                   ( Result : 25.00378,  Loss : 0.0,  Steps : 1000,  Global Steps : 540000 )\n",
      "541           14.669\n",
      "                   ( Result : 17.7343,  Loss : 0.0,  Steps : 1000,  Global Steps : 541000 )\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Nesting violated for default stack of <class 'tensorflow.python.client.session.Session'> objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51c0b5cb052e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mending_cond_epis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mending_cond_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                       Game = 'Swimmer-v1', case_n = i+1)\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exec_type, exec_value, exec_tb)\u001b[0m\n\u001b[1;32m   1501\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session closing due to OpError: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     self._default_session_context_manager.__exit__(\n\u001b[0;32m-> 1503\u001b[0;31m         exec_type, exec_value, exec_tb)\n\u001b[0m\u001b[1;32m   1504\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   4343\u001b[0m           raise AssertionError(\n\u001b[1;32m   4344\u001b[0m               \u001b[0;34m\"Nesting violated for default stack of %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m               type(default))\n\u001b[0m\u001b[1;32m   4346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Nesting violated for default stack of <class 'tensorflow.python.client.session.Session'> objects"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Strategy_DDPG import DDPG\n",
    "\n",
    "case_num = 3\n",
    "\n",
    "#seed_list = [0, 0, 0]\n",
    "\n",
    "batch_list = [128, 32, 512]\n",
    "Q_l_rate_list = [0.0002, 0.0005, 0.001]\n",
    "A_l_rate_list = [0.0002, 0.0005, 0.001]\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "for i in range(case_num):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session(config=config) as sess :\n",
    "        \n",
    "        Swimmer = DDPG(sess, dis = 0.99, REPLAY_MEMORY = 100000, max_episodes = 800, seed_n = 0,\n",
    "                      \n",
    "                      batch_size = 64, tau = 0.001, save_epi = 100,\n",
    "                      \n",
    "                      layer_size_Q1 = 400, layer_size_Q2 = 300, learning_rate_Q = 0.00001,\n",
    "                      layer_size_A1 = 400, layer_size_A2 = 300, learning_rate_A = 0.00001,\n",
    "                      \n",
    "                      ending_cond_epis = 100, ending_cond_reward = 360,\n",
    "                      Game = 'Swimmer-v1', case_n = i+1)\n",
    "    sess.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
